{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "749b61a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "19f856f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "model = ChatGoogleGenerativeAI(model='gemini-2.0-flash')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce9c010",
   "metadata": {},
   "source": [
    "# Taking video id for doc loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "6ca725e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello all, my name is Krishna and welcome to my YouTube channel. So guys, today in this particular video we are going to discuss about the basic differences between generative AI versus AI agents versus agentic AI. Now this is one of the most trending topics that is currently going on and it is necessary that you need to have your understanding very much clear when you are specifically working in all the specific topics. Okay. So one by one we will try to understand about each and every topics that I have actually mentioned over here. We'll go step by step. Okay. So first thing is that I hope you may be knowing large language models. Okay. You may be knowing about large image models also. Right? So let's say that I'll also go ahead and write large image models. When we talk about large language models or large image model, these models are actually very huge models, right? These are like huge models, bigger models, right? It can be of billions of parameters and they have trained with huge amount of data, right? This data that it is specifically used to train this model is huge. So you may have seen various models like llama 3. You may have been seeing OpenAI models right from GPT4 to GPT4 mini. Many many different models are there. And these models are specifically trained with huge amount of data. And at the end of the day, all these particular models are generating what are they basically doing? They're generating new content, right? Generating new content. Now, when we talk about generating new content, the models can probably generate new images, it can generate new text, it can generate video frames, it can generate anything as such, right? audio it can also generate audio right and it can also generate videos so I've written each and everything about over here right so here what this LLM is basically doing since it is trained with huge amount of data in short it is basically generating new content whenever we try to give any kind of input right if I say hey please generate a new image related to aentic AI so this LLA model it if it has that multimodel capabilities it will be able to generate that particular image or video whatever specific things we require whenever we talk in this specific way this is something related to generative AI okay so this is something related to generative AI right now when we say hey uh let's go ahead and build a generative AI application wherein we create a chatbot okay and that chatbot should be able to do this specific ch uh task wherein the main aim is generating new content you can definitely do it right so There we specifically say hey we are specifically working in generative AI applications right here the most important thing is that there's some few properties that everybody should keep in mind right whenever we talk about generative AI application these are specifically reactive okay reactive there is this word that we use which we basically say it as reactive now what does this basically reactive mean right see in order to work with this LLM models right we definitely have to write some kind of prompts okay prompts and based on this particular prompt this LLM model will generate new content this is really important to understand now what does this prompt basically means this prompt is just like some sentence where we specify something and we tell the LLM to behave in that way I may say hey that uh hey please try to uh act as a data scientist and take an interview for me right so I that is a kind of prompt that is a kind of instruction that I'm actually giving to the LLM model right so here the most important thing with respect to the generative AI content uh generative AI application is that obviously you will be having some kind of models LLM models LM models multimodel right along with these models we specifically write prompts right like how this particular LML model should be behaving and that is how it'll go ahead and generate the new content. Okay. So this is with respect to the generative AI applications. Right? Here uh there are lot of different different kind of libraries. There are libraries like langraph right. There are libraries like lang chain which you can specifically use and you can get started with right lang chain. There are different different libraries like let's say llama index. Llama index right? If you don't want to go ahead and use this you can also go ahead and use grock. Grock also has a specific set of code or you can also go ahead and use OpenAI code in order to probably go ahead and start working and developing geni applications. Okay. Now this is one of the thing. Okay. Now the next two topics that we are specifically going to discuss about is something called as AI agents and agentic AI. And this is super important right now because the thing that we work on right agentic AI application it is trending in every field. people are thinking that how they can automate the entire complex task the entire workflow with the help of agent application and obviously bring human feedback in between them. Okay. Now let's go ahead and discuss about this and I hope I have already made a video related to generative way. I have developed so many different videos from lang chain to lang graph you can definitely go ahead and watch. Okay. Now let's go ahead and discuss about the second thing which is nothing but the second category that we're going to focus on is AI agents versus agentic AI versus agentic AI. Now people do think that AI agents and agentic AI one and the same but it is not like that. Okay. So here just please focus on for the next 10 minutes because I'm going to explain each and everything that you really need to understand and that is how you'll be able to understand between what is the basic difference between AI agents and agent AI. Okay. Now let's say that I have some kind of LLMs. Okay. So let's say and at all these places LLM is the most important thing right because LLM is something that will be acting like an AI agent. It can act like an AI agent. it can also work in an agentic AI application. Okay. And it will it will be very important how this AI agents is different when compared to the LLM also. Okay. So let's say that I have a specific LLM. Okay. And now this LLM can be any model. Okay. Let's let's consider that it is it is some model that we are going to use from graph. It can be lama 3. We are using this specific model. Okay. Now you know that all these LLM or LM models they're trained with some specific past data okay they don't have like let's say if I ask this particular LLM hey what is the news for today or hey or who won this particular IPL match between this and this like let's say Bangalore is going to happen have some matches tomorrow or today if it has right and LLM will not know the result because it's not connected to the internet okay so in that kind of scenario Whenever I ask this particular question, the LLM will not be able to give an output to us. Okay, obviously it will not be able to give because it does not have that specific information. Now, this is one major disadvantage of LLM, right? Yes, LLM will be able to generate new content. These models will be able to generate the new content. But what about the current information? Okay, it will not be able to give you, right? Let's say that I'm going to ask some specific information of a company. Obviously this LLM will not be trained with that company data because the company data will be private to that company itself. Right? So that way also that LLM will not be able to give you that unless and until it is connected to some kind of external database or external data source. This is just one example now what is basically happening is that as soon as I asked a question hey who won this particular match within RCB or any other place any other um any other team that happened today it will not be able to give you the output. So what it will be dependent on it will be dependent on the third party source. Let's say there is one third party source I will consider in this particular scenario. I will just go ahead and connect it to some kind of database. Okay. Let's say one of the data source is something called as taby. I will go ahead and write tabi. So if you don't know about tabi it provides you some kind of internet search. Okay. It you can use that particular API. You can write this specific wrapper and you can probably go ahead and write this. Now the question arises how this llm is basically going to call this tavly API. Now there is one very important property if you're learning lang chain or lang graph any of the specific libraries there is a concept of something called as tool call. Tool call. Okay tool call. Now what is this tool call? Let's say that if the LLM is not able to provide the response for this particular input, it will keep on looking for external things that will be able to handle this particular input. Now in this particular case when I ask the input saying that hey what is the current news? What is the current news for this specific date that is today's date? The LLM will not be able to give the answer. So the LLM will look for whether it is connected to any third-party APIs, third party APIs or data source from which I will be able to get this kind of information. So that is where it will be making the specific tool call. Okay, it will be making the specific tool call. Now this tool call will be something like this. The tool call will be made and based on this I will be getting a response. Okay, I'll be getting a response. Now the as soon as the LLM made this tool call the it got this specific response. So this is my request and this is my response. Okay, this is my response and as soon as I got the response the LLM is smart enough to finally summarize that particular output uh that response and give you the output and this is what I'm actually looking for. Okay. Now you need to really understand over here the kind of task that is happening right a request is going I'm getting the information I'm getting giving back the response this is basically happening by an AI agent just a single AI agent I can consider this as an AI agent okay here my main aim is that I have asked an input saying that hey give me the some current information about today AI news I really want to see for this particular date AI news which my LLM was not able to do it. So what it has done is that the LLM is smart enough to understand which tool to probably call and based on this tool call functional it is calling this and it is getting the response. So this is a specific task okay and this task is basically solved by this tavly okay tavly which is responsible for the internet search. So this task can be considered as an AI agent. Okay, for a specific task we have defined this. Okay, very simple definition. Okay, so for a specific task we are able to probably go ahead and call this and we are getting the response. Now the question rises, now the question rises then what is agentic AI? AI agents have understood okay fine for a specific task I'm calling something from the LLM, right? The LM is responsible for making that tool call and getting the output and summarizing the output and giving it over here. Here also we can add the prompt. Here also once I get the response I can add the prompt and based on that I can summarize the output. I can do that. Okay. But this is only for one kind of task. Now if I talk about agentic AI okay and for discussing about the agentic AI application let's consider that let's consider that I have a task and this task is nothing but let's consider I want to probably convert a YT video that I really want to upload to a blog okay to a blog and now to convert a YT video YouTube video into a blog let's say that I have been uploading so many videos. Just imagine if I just create an agenti system which takes my YouTube video and convert that into a blog and publish it in my website. Would it will that not be good? It will definitely be good. Right now here if I probably see I can divide this into multiple subtask. First of all I will take this YT video. I will convert I will take the transcript from the YT video. Transcript from the YT video. Okay. After considering the transcript from this my second task will be creating title. Creating title. Okay. Third it can be creating description. Okay. So this will be my third task creating description and my fourth task will be writing the conclusion. Let's say so I've defined this task into four different task right four different tasks. Now for the same task, don't you think converting a YT YT video into transcript, I can create one AI agent. Then similarly for my second AI agent, I can basically take this transcript and this AI agent should be able to give me the title. Yeah. Yeah. And just to show you how these things will happen, don't you think I can just go ahead see this? Okay, see this magic. Okay. So, so what what I will be doing is that my first task will be that this AI agent will be responsible in getting me the transcript from my YouTube video. Okay. This AI agent will be responsible for creating the title from the transcript that I get. Okay. Then my next agent over here which will be parallelly will be responsible to probably create the description from this particular transcript. Yeah. And finally, don't you think I can have one more one more AI agent which will be responsible in creating the conclusion. Right? Now here this is my AI agent one. Let's consider this. Okay. So this is my AI agent one. This is my AI agent 2. This is my AI agent three. And this is my AI agent 4. Each and every agent can use LLM. It can use prompt to perform its task. Each each here it can or it cannot it is not composite it needs to use all the LLM but since we are working with respect to text related things then obviously we can use LLM okay for now this is just like a one kind of workflow so this workflow goes on like this right so first of all I give my YT video URL YT video URL then this agent is responsible in taking from this and giving the output a transcript. Now this transcript is sent to all the agents and finally we can combine all these outputs and give my final blog. Right? So what does this basically mean? Before an AI agent only used to do one task in an agentic AI system. So this is my entire complex workflow with respect to my agentic AI system and this is performing this entire task together. Here every agent is communicating with each other. Right? I can add one more thing over here. I can add human feedback. Human feedback also over here. So here what is basically happening? AI agents are communicating with each other. Right. I can also make sure to probably before this AI agent, let's say this agent is responsible in probably creating a description. For creating a description, it also wants the title. So it will just go ahead this AI agent 2 whatever output it is creating for the title, it will give it to the agent 3. And this will take that information and do this. So internally you'll be able to see we can also make this agent communicate with each other to solve a complex workflow and finally achieve a goal. Right? So just to understand what is the difference between AI agents versus agentic AI here AI agent is doing only one task. In an agentic AI system this AI agents will be collaborating with each other. This is really important. Collaborating collaborating with each other to solve a goal. This is really really important to understand. So I hope you understood this particular video. I hope you liked this particular video. This was the basic differences between generative AI versus AI agent versus agentic AI. And I hope you are able to understand this. Okay. Similar kind of videos I'm also going to come up in this specific series so that you get your fundamental rights. I hope you like this particular video. This was it from my side. I'll see you in the next video. Have a great day. Thank you and all. Take care. Bye-bye.\n"
     ]
    }
   ],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n",
    "\n",
    "video_id = \"p4pHsuEf4Ms\"\n",
    "\n",
    "try:\n",
    "    # Try preferred language first\n",
    "    try:\n",
    "        transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=[\"en\"])\n",
    "    except NoTranscriptFound:\n",
    "        print(\"Hindi transcript not found, falling back to English.\")\n",
    "        transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=[\"hi\"])\n",
    "\n",
    "    transcript = \" \".join(chunk[\"text\"] for chunk in transcript_list)\n",
    "    print(transcript)\n",
    "\n",
    "except TranscriptsDisabled:\n",
    "    print(\"Captions are disabled for this video.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "4277032c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello all, my name is Krishna and welcome to my YouTube channel. So guys, today in this particular video we are going to discuss about the basic differences between generative AI versus AI agents versus agentic AI. Now this is one of the most trending topics that is currently going on and it is necessary that you need to have your understanding very much clear when you are specifically working in all the specific topics. Okay. So one by one we will try to understand about each and every topics that I have actually mentioned over here. We'll go step by step. Okay. So first thing is that I hope you may be knowing large language models. Okay. You may be knowing about large image models also. Right? So let's say that I'll also go ahead and write large image models. When we talk about large language models or large image model, these models are actually very huge models, right? These are like huge models, bigger models, right? It can be of billions of parameters and they have trained with huge amount of data, right? This data that it is specifically used to train this model is huge. So you may have seen various models like llama 3. You may have been seeing OpenAI models right from GPT4 to GPT4 mini. Many many different models are there. And these models are specifically trained with huge amount of data. And at the end of the day, all these particular models are generating what are they basically doing? They're generating new content, right? Generating new content. Now, when we talk about generating new content, the models can probably generate new images, it can generate new text, it can generate video frames, it can generate anything as such, right? audio it can also generate audio right and it can also generate videos so I've written each and everything about over here right so here what this LLM is basically doing since it is trained with huge amount of data in short it is basically generating new content whenever we try to give any kind of input right if I say hey please generate a new image related to aentic AI so this LLA model it if it has that multimodel capabilities it will be able to generate that particular image or video whatever specific things we require whenever we talk in this specific way this is something related to generative AI okay so this is something related to generative AI right now when we say hey uh let's go ahead and build a generative AI application wherein we create a chatbot okay and that chatbot should be able to do this specific ch uh task wherein the main aim is generating new content you can definitely do it right so There we specifically say hey we are specifically working in generative AI applications right here the most important thing is that there's some few properties that everybody should keep in mind right whenever we talk about generative AI application these are specifically reactive okay reactive there is this word that we use which we basically say it as reactive now what does this basically reactive mean right see in order to work with this LLM models right we definitely have to write some kind of prompts okay prompts and based on this particular prompt this LLM model will generate new content this is really important to understand now what does this prompt basically means this prompt is just like some sentence where we specify something and we tell the LLM to behave in that way I may say hey that uh hey please try to uh act as a data scientist and take an interview for me right so I that is a kind of prompt that is a kind of instruction that I'm actually giving to the LLM model right so here the most important thing with respect to the generative AI content uh generative AI application is that obviously you will be having some kind of models LLM models LM models multimodel right along with these models we specifically write prompts right like how this particular LML model should be behaving and that is how it'll go ahead and generate the new content. Okay. So this is with respect to the generative AI applications. Right? Here uh there are lot of different different kind of libraries. There are libraries like langraph right. There are libraries like lang chain which you can specifically use and you can get started with right lang chain. There are different different libraries like let's say llama index. Llama index right? If you don't want to go ahead and use this you can also go ahead and use grock. Grock also has a specific set of code or you can also go ahead and use OpenAI code in order to probably go ahead and start working and developing geni applications. Okay. Now this is one of the thing. Okay. Now the next two topics that we are specifically going to discuss about is something called as AI agents and agentic AI. And this is super important right now because the thing that we work on right agentic AI application it is trending in every field. people are thinking that how they can automate the entire complex task the entire workflow with the help of agent application and obviously bring human feedback in between them. Okay. Now let's go ahead and discuss about this and I hope I have already made a video related to generative way. I have developed so many different videos from lang chain to lang graph you can definitely go ahead and watch. Okay. Now let's go ahead and discuss about the second thing which is nothing but the second category that we're going to focus on is AI agents versus agentic AI versus agentic AI. Now people do think that AI agents and agentic AI one and the same but it is not like that. Okay. So here just please focus on for the next 10 minutes because I'm going to explain each and everything that you really need to understand and that is how you'll be able to understand between what is the basic difference between AI agents and agent AI. Okay. Now let's say that I have some kind of LLMs. Okay. So let's say and at all these places LLM is the most important thing right because LLM is something that will be acting like an AI agent. It can act like an AI agent. it can also work in an agentic AI application. Okay. And it will it will be very important how this AI agents is different when compared to the LLM also. Okay. So let's say that I have a specific LLM. Okay. And now this LLM can be any model. Okay. Let's let's consider that it is it is some model that we are going to use from graph. It can be lama 3. We are using this specific model. Okay. Now you know that all these LLM or LM models they're trained with some specific past data okay they don't have like let's say if I ask this particular LLM hey what is the news for today or hey or who won this particular IPL match between this and this like let's say Bangalore is going to happen have some matches tomorrow or today if it has right and LLM will not know the result because it's not connected to the internet okay so in that kind of scenario Whenever I ask this particular question, the LLM will not be able to give an output to us. Okay, obviously it will not be able to give because it does not have that specific information. Now, this is one major disadvantage of LLM, right? Yes, LLM will be able to generate new content. These models will be able to generate the new content. But what about the current information? Okay, it will not be able to give you, right? Let's say that I'm going to ask some specific information of a company. Obviously this LLM will not be trained with that company data because the company data will be private to that company itself. Right? So that way also that LLM will not be able to give you that unless and until it is connected to some kind of external database or external data source. This is just one example now what is basically happening is that as soon as I asked a question hey who won this particular match within RCB or any other place any other um any other team that happened today it will not be able to give you the output. So what it will be dependent on it will be dependent on the third party source. Let's say there is one third party source I will consider in this particular scenario. I will just go ahead and connect it to some kind of database. Okay. Let's say one of the data source is something called as taby. I will go ahead and write tabi. So if you don't know about tabi it provides you some kind of internet search. Okay. It you can use that particular API. You can write this specific wrapper and you can probably go ahead and write this. Now the question arises how this llm is basically going to call this tavly API. Now there is one very important property if you're learning lang chain or lang graph any of the specific libraries there is a concept of something called as tool call. Tool call. Okay tool call. Now what is this tool call? Let's say that if the LLM is not able to provide the response for this particular input, it will keep on looking for external things that will be able to handle this particular input. Now in this particular case when I ask the input saying that hey what is the current news? What is the current news for this specific date that is today's date? The LLM will not be able to give the answer. So the LLM will look for whether it is connected to any third-party APIs, third party APIs or data source from which I will be able to get this kind of information. So that is where it will be making the specific tool call. Okay, it will be making the specific tool call. Now this tool call will be something like this. The tool call will be made and based on this I will be getting a response. Okay, I'll be getting a response. Now the as soon as the LLM made this tool call the it got this specific response. So this is my request and this is my response. Okay, this is my response and as soon as I got the response the LLM is smart enough to finally summarize that particular output uh that response and give you the output and this is what I'm actually looking for. Okay. Now you need to really understand over here the kind of task that is happening right a request is going I'm getting the information I'm getting giving back the response this is basically happening by an AI agent just a single AI agent I can consider this as an AI agent okay here my main aim is that I have asked an input saying that hey give me the some current information about today AI news I really want to see for this particular date AI news which my LLM was not able to do it. So what it has done is that the LLM is smart enough to understand which tool to probably call and based on this tool call functional it is calling this and it is getting the response. So this is a specific task okay and this task is basically solved by this tavly okay tavly which is responsible for the internet search. So this task can be considered as an AI agent. Okay, for a specific task we have defined this. Okay, very simple definition. Okay, so for a specific task we are able to probably go ahead and call this and we are getting the response. Now the question rises, now the question rises then what is agentic AI? AI agents have understood okay fine for a specific task I'm calling something from the LLM, right? The LM is responsible for making that tool call and getting the output and summarizing the output and giving it over here. Here also we can add the prompt. Here also once I get the response I can add the prompt and based on that I can summarize the output. I can do that. Okay. But this is only for one kind of task. Now if I talk about agentic AI okay and for discussing about the agentic AI application let's consider that let's consider that I have a task and this task is nothing but let's consider I want to probably convert a YT video that I really want to upload to a blog okay to a blog and now to convert a YT video YouTube video into a blog let's say that I have been uploading so many videos. Just imagine if I just create an agenti system which takes my YouTube video and convert that into a blog and publish it in my website. Would it will that not be good? It will definitely be good. Right now here if I probably see I can divide this into multiple subtask. First of all I will take this YT video. I will convert I will take the transcript from the YT video. Transcript from the YT video. Okay. After considering the transcript from this my second task will be creating title. Creating title. Okay. Third it can be creating description. Okay. So this will be my third task creating description and my fourth task will be writing the conclusion. Let's say so I've defined this task into four different task right four different tasks. Now for the same task, don't you think converting a YT YT video into transcript, I can create one AI agent. Then similarly for my second AI agent, I can basically take this transcript and this AI agent should be able to give me the title. Yeah. Yeah. And just to show you how these things will happen, don't you think I can just go ahead see this? Okay, see this magic. Okay. So, so what what I will be doing is that my first task will be that this AI agent will be responsible in getting me the transcript from my YouTube video. Okay. This AI agent will be responsible for creating the title from the transcript that I get. Okay. Then my next agent over here which will be parallelly will be responsible to probably create the description from this particular transcript. Yeah. And finally, don't you think I can have one more one more AI agent which will be responsible in creating the conclusion. Right? Now here this is my AI agent one. Let's consider this. Okay. So this is my AI agent one. This is my AI agent 2. This is my AI agent three. And this is my AI agent 4. Each and every agent can use LLM. It can use prompt to perform its task. Each each here it can or it cannot it is not composite it needs to use all the LLM but since we are working with respect to text related things then obviously we can use LLM okay for now this is just like a one kind of workflow so this workflow goes on like this right so first of all I give my YT video URL YT video URL then this agent is responsible in taking from this and giving the output a transcript. Now this transcript is sent to all the agents and finally we can combine all these outputs and give my final blog. Right? So what does this basically mean? Before an AI agent only used to do one task in an agentic AI system. So this is my entire complex workflow with respect to my agentic AI system and this is performing this entire task together. Here every agent is communicating with each other. Right? I can add one more thing over here. I can add human feedback. Human feedback also over here. So here what is basically happening? AI agents are communicating with each other. Right. I can also make sure to probably before this AI agent, let's say this agent is responsible in probably creating a description. For creating a description, it also wants the title. So it will just go ahead this AI agent 2 whatever output it is creating for the title, it will give it to the agent 3. And this will take that information and do this. So internally you'll be able to see we can also make this agent communicate with each other to solve a complex workflow and finally achieve a goal. Right? So just to understand what is the difference between AI agents versus agentic AI here AI agent is doing only one task. In an agentic AI system this AI agents will be collaborating with each other. This is really important. Collaborating collaborating with each other to solve a goal. This is really really important to understand. So I hope you understood this particular video. I hope you liked this particular video. This was the basic differences between generative AI versus AI agent versus agentic AI. And I hope you are able to understand this. Okay. Similar kind of videos I'm also going to come up in this specific series so that you get your fundamental rights. I hope you like this particular video. This was it from my side. I'll see you in the next video. Have a great day. Thank you and all. Take care. Bye-bye.\""
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "edc7009f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Hello all, my name is Krishna and', 'start': 0.48, 'duration': 4.0},\n",
       " {'text': 'welcome to my YouTube channel. So guys,',\n",
       "  'start': 2.56,\n",
       "  'duration': 3.6},\n",
       " {'text': 'today in this particular video we are',\n",
       "  'start': 4.48,\n",
       "  'duration': 3.359},\n",
       " {'text': 'going to discuss about the basic', 'start': 6.16, 'duration': 4.16},\n",
       " {'text': 'differences between generative AI versus',\n",
       "  'start': 7.839,\n",
       "  'duration': 5.84},\n",
       " {'text': 'AI agents versus agentic AI. Now this is',\n",
       "  'start': 10.32,\n",
       "  'duration': 5.519},\n",
       " {'text': 'one of the most trending topics that is',\n",
       "  'start': 13.679,\n",
       "  'duration': 3.921},\n",
       " {'text': 'currently going on and it is necessary',\n",
       "  'start': 15.839,\n",
       "  'duration': 4.401},\n",
       " {'text': 'that you need to have your understanding',\n",
       "  'start': 17.6,\n",
       "  'duration': 4.48},\n",
       " {'text': 'very much clear when you are', 'start': 20.24, 'duration': 3.76},\n",
       " {'text': 'specifically working in all the specific',\n",
       "  'start': 22.08,\n",
       "  'duration': 5.119},\n",
       " {'text': 'topics. Okay. So one by one we will try',\n",
       "  'start': 24.0,\n",
       "  'duration': 5.039},\n",
       " {'text': 'to understand about each and every',\n",
       "  'start': 27.199,\n",
       "  'duration': 3.121},\n",
       " {'text': 'topics that I have actually mentioned',\n",
       "  'start': 29.039,\n",
       "  'duration': 3.761},\n",
       " {'text': \"over here. We'll go step by step. Okay.\",\n",
       "  'start': 30.32,\n",
       "  'duration': 4.8},\n",
       " {'text': 'So first thing is that I hope you may be',\n",
       "  'start': 32.8,\n",
       "  'duration': 5.04},\n",
       " {'text': 'knowing large language models. Okay. You',\n",
       "  'start': 35.12,\n",
       "  'duration': 5.599},\n",
       " {'text': 'may be knowing about large image models',\n",
       "  'start': 37.84,\n",
       "  'duration': 5.44},\n",
       " {'text': \"also. Right? So let's say that I'll also\",\n",
       "  'start': 40.719,\n",
       "  'duration': 5.041},\n",
       " {'text': 'go ahead and write large image models.',\n",
       "  'start': 43.28,\n",
       "  'duration': 4.24},\n",
       " {'text': 'When we talk about large language models',\n",
       "  'start': 45.76,\n",
       "  'duration': 5.68},\n",
       " {'text': 'or large image model, these models are',\n",
       "  'start': 47.52,\n",
       "  'duration': 7.12},\n",
       " {'text': 'actually very huge models, right? These',\n",
       "  'start': 51.44,\n",
       "  'duration': 5.439},\n",
       " {'text': 'are like huge models, bigger models,',\n",
       "  'start': 54.64,\n",
       "  'duration': 4.16},\n",
       " {'text': 'right? It can be of billions of',\n",
       "  'start': 56.879,\n",
       "  'duration': 4.32},\n",
       " {'text': 'parameters and they have trained with',\n",
       "  'start': 58.8,\n",
       "  'duration': 5.12},\n",
       " {'text': 'huge amount of data, right? This data',\n",
       "  'start': 61.199,\n",
       "  'duration': 4.561},\n",
       " {'text': 'that it is specifically used to train',\n",
       "  'start': 63.92,\n",
       "  'duration': 4.4},\n",
       " {'text': 'this model is huge. So you may have seen',\n",
       "  'start': 65.76,\n",
       "  'duration': 5.6},\n",
       " {'text': 'various models like llama 3. You may',\n",
       "  'start': 68.32,\n",
       "  'duration': 5.119},\n",
       " {'text': 'have been seeing OpenAI models right',\n",
       "  'start': 71.36,\n",
       "  'duration': 6.079},\n",
       " {'text': 'from GPT4 to GPT4 mini. Many many',\n",
       "  'start': 73.439,\n",
       "  'duration': 5.281},\n",
       " {'text': 'different models are there. And these',\n",
       "  'start': 77.439,\n",
       "  'duration': 2.801},\n",
       " {'text': 'models are specifically trained with',\n",
       "  'start': 78.72,\n",
       "  'duration': 4.0},\n",
       " {'text': 'huge amount of data. And at the end of',\n",
       "  'start': 80.24,\n",
       "  'duration': 5.8},\n",
       " {'text': 'the day, all these particular models are',\n",
       "  'start': 82.72,\n",
       "  'duration': 5.439},\n",
       " {'text': 'generating what are they basically',\n",
       "  'start': 86.04,\n",
       "  'duration': 4.32},\n",
       " {'text': \"doing? They're generating new content,\",\n",
       "  'start': 88.159,\n",
       "  'duration': 5.081},\n",
       " {'text': 'right? Generating new', 'start': 90.36, 'duration': 5.0},\n",
       " {'text': 'content. Now, when we talk about',\n",
       "  'start': 93.24,\n",
       "  'duration': 4.68},\n",
       " {'text': 'generating new content, the models can',\n",
       "  'start': 95.36,\n",
       "  'duration': 4.6},\n",
       " {'text': 'probably generate new', 'start': 97.92, 'duration': 5.4},\n",
       " {'text': 'images, it can generate new text, it can',\n",
       "  'start': 99.96,\n",
       "  'duration': 6.28},\n",
       " {'text': 'generate video frames, it can generate',\n",
       "  'start': 103.32,\n",
       "  'duration': 5.159},\n",
       " {'text': 'anything as such, right?', 'start': 106.24, 'duration': 5.44},\n",
       " {'text': 'audio it can also generate audio right',\n",
       "  'start': 108.479,\n",
       "  'duration': 5.361},\n",
       " {'text': \"and it can also generate videos so I've\",\n",
       "  'start': 111.68,\n",
       "  'duration': 3.759},\n",
       " {'text': 'written each and everything about over',\n",
       "  'start': 113.84,\n",
       "  'duration': 4.559},\n",
       " {'text': 'here right so here what this LLM is',\n",
       "  'start': 115.439,\n",
       "  'duration': 4.481},\n",
       " {'text': 'basically doing since it is trained with',\n",
       "  'start': 118.399,\n",
       "  'duration': 3.921},\n",
       " {'text': 'huge amount of data in short it is',\n",
       "  'start': 119.92,\n",
       "  'duration': 3.839},\n",
       " {'text': 'basically generating new content',\n",
       "  'start': 122.32,\n",
       "  'duration': 3.439},\n",
       " {'text': 'whenever we try to give any kind of',\n",
       "  'start': 123.759,\n",
       "  'duration': 4.401},\n",
       " {'text': 'input right if I say hey please generate',\n",
       "  'start': 125.759,\n",
       "  'duration': 5.361},\n",
       " {'text': 'a new image related to aentic AI so this',\n",
       "  'start': 128.16,\n",
       "  'duration': 5.84},\n",
       " {'text': 'LLA model it if it has that multimodel',\n",
       "  'start': 131.12,\n",
       "  'duration': 4.88},\n",
       " {'text': 'capabilities it will be able to generate',\n",
       "  'start': 134.0,\n",
       "  'duration': 4.239},\n",
       " {'text': 'that particular image or video whatever',\n",
       "  'start': 136.0,\n",
       "  'duration': 4.56},\n",
       " {'text': 'specific things we require whenever we',\n",
       "  'start': 138.239,\n",
       "  'duration': 4.321},\n",
       " {'text': 'talk in this specific way this is',\n",
       "  'start': 140.56,\n",
       "  'duration': 4.72},\n",
       " {'text': 'something related to generative AI okay',\n",
       "  'start': 142.56,\n",
       "  'duration': 4.319},\n",
       " {'text': 'so this is something related to', 'start': 145.28, 'duration': 4.8},\n",
       " {'text': 'generative AI right now when we say hey',\n",
       "  'start': 146.879,\n",
       "  'duration': 4.801},\n",
       " {'text': \"uh let's go ahead and build a generative\",\n",
       "  'start': 150.08,\n",
       "  'duration': 5.0},\n",
       " {'text': 'AI application wherein we create a',\n",
       "  'start': 151.68,\n",
       "  'duration': 6.8},\n",
       " {'text': 'chatbot okay and that chatbot should be',\n",
       "  'start': 155.08,\n",
       "  'duration': 6.519},\n",
       " {'text': 'able to do this specific ch uh task',\n",
       "  'start': 158.48,\n",
       "  'duration': 5.36},\n",
       " {'text': 'wherein the main aim is generating new',\n",
       "  'start': 161.599,\n",
       "  'duration': 4.801},\n",
       " {'text': 'content you can definitely do it right',\n",
       "  'start': 163.84,\n",
       "  'duration': 4.88},\n",
       " {'text': 'so There we specifically say hey we are',\n",
       "  'start': 166.4,\n",
       "  'duration': 4.16},\n",
       " {'text': 'specifically working in generative AI',\n",
       "  'start': 168.72,\n",
       "  'duration': 5.04},\n",
       " {'text': 'applications right here the most',\n",
       "  'start': 170.56,\n",
       "  'duration': 5.44},\n",
       " {'text': \"important thing is that there's some few\",\n",
       "  'start': 173.76,\n",
       "  'duration': 4.16},\n",
       " {'text': 'properties that everybody should keep in',\n",
       "  'start': 176.0,\n",
       "  'duration': 3.68},\n",
       " {'text': 'mind right whenever we talk about',\n",
       "  'start': 177.92,\n",
       "  'duration': 4.399},\n",
       " {'text': 'generative AI application these are',\n",
       "  'start': 179.68,\n",
       "  'duration': 3.96},\n",
       " {'text': 'specifically', 'start': 182.319, 'duration': 4.161},\n",
       " {'text': 'reactive okay reactive there is this',\n",
       "  'start': 183.64,\n",
       "  'duration': 5.16},\n",
       " {'text': 'word that we use which we basically say',\n",
       "  'start': 186.48,\n",
       "  'duration': 4.56},\n",
       " {'text': 'it as reactive now what does this',\n",
       "  'start': 188.8,\n",
       "  'duration': 6.32},\n",
       " {'text': 'basically reactive mean right see in',\n",
       "  'start': 191.04,\n",
       "  'duration': 6.559},\n",
       " {'text': 'order to work with this LLM models right',\n",
       "  'start': 195.12,\n",
       "  'duration': 5.24},\n",
       " {'text': 'we definitely have to write some kind of',\n",
       "  'start': 197.599,\n",
       "  'duration': 6.72},\n",
       " {'text': 'prompts okay prompts and based on this',\n",
       "  'start': 200.36,\n",
       "  'duration': 6.2},\n",
       " {'text': 'particular prompt this LLM model will',\n",
       "  'start': 204.319,\n",
       "  'duration': 4.241},\n",
       " {'text': 'generate new content this is really',\n",
       "  'start': 206.56,\n",
       "  'duration': 4.08},\n",
       " {'text': 'important to understand now what does',\n",
       "  'start': 208.56,\n",
       "  'duration': 4.88},\n",
       " {'text': 'this prompt basically means this prompt',\n",
       "  'start': 210.64,\n",
       "  'duration': 6.0},\n",
       " {'text': 'is just like some sentence where we',\n",
       "  'start': 213.44,\n",
       "  'duration': 5.359},\n",
       " {'text': 'specify something and we tell the LLM to',\n",
       "  'start': 216.64,\n",
       "  'duration': 4.64},\n",
       " {'text': 'behave in that way I may say hey that uh',\n",
       "  'start': 218.799,\n",
       "  'duration': 5.841},\n",
       " {'text': 'hey please try to uh act as a data',\n",
       "  'start': 221.28,\n",
       "  'duration': 5.599},\n",
       " {'text': 'scientist and take an interview for me',\n",
       "  'start': 224.64,\n",
       "  'duration': 4.959},\n",
       " {'text': 'right so I that is a kind of prompt that',\n",
       "  'start': 226.879,\n",
       "  'duration': 4.561},\n",
       " {'text': \"is a kind of instruction that I'm\",\n",
       "  'start': 229.599,\n",
       "  'duration': 4.56},\n",
       " {'text': 'actually giving to the LLM model right',\n",
       "  'start': 231.44,\n",
       "  'duration': 5.04},\n",
       " {'text': 'so here the most important thing with',\n",
       "  'start': 234.159,\n",
       "  'duration': 4.241},\n",
       " {'text': 'respect to the generative AI content uh',\n",
       "  'start': 236.48,\n",
       "  'duration': 3.679},\n",
       " {'text': 'generative AI application is that',\n",
       "  'start': 238.4,\n",
       "  'duration': 3.839},\n",
       " {'text': 'obviously you will be having some kind',\n",
       "  'start': 240.159,\n",
       "  'duration': 4.36},\n",
       " {'text': 'of models LLM models LM models',\n",
       "  'start': 242.239,\n",
       "  'duration': 5.041},\n",
       " {'text': 'multimodel right along with these models',\n",
       "  'start': 244.519,\n",
       "  'duration': 5.321},\n",
       " {'text': 'we specifically write prompts right like',\n",
       "  'start': 247.28,\n",
       "  'duration': 5.28},\n",
       " {'text': 'how this particular LML model should be',\n",
       "  'start': 249.84,\n",
       "  'duration': 4.959},\n",
       " {'text': \"behaving and that is how it'll go ahead\",\n",
       "  'start': 252.56,\n",
       "  'duration': 4.48},\n",
       " {'text': 'and generate the new content. Okay. So',\n",
       "  'start': 254.799,\n",
       "  'duration': 3.761},\n",
       " {'text': 'this is with respect to the generative',\n",
       "  'start': 257.04,\n",
       "  'duration': 4.64},\n",
       " {'text': 'AI applications. Right? Here uh there',\n",
       "  'start': 258.56,\n",
       "  'duration': 4.639},\n",
       " {'text': 'are lot of different different kind of',\n",
       "  'start': 261.68,\n",
       "  'duration': 3.56},\n",
       " {'text': 'libraries. There are libraries like',\n",
       "  'start': 263.199,\n",
       "  'duration': 4.961},\n",
       " {'text': 'langraph right. There are libraries like',\n",
       "  'start': 265.24,\n",
       "  'duration': 4.92},\n",
       " {'text': 'lang chain which you can specifically',\n",
       "  'start': 268.16,\n",
       "  'duration': 5.039},\n",
       " {'text': 'use and you can get started with right',\n",
       "  'start': 270.16,\n",
       "  'duration': 4.56},\n",
       " {'text': 'lang chain. There are different',\n",
       "  'start': 273.199,\n",
       "  'duration': 3.72},\n",
       " {'text': \"different libraries like let's say llama\",\n",
       "  'start': 274.72,\n",
       "  'duration': 5.919},\n",
       " {'text': \"index. Llama index right? If you don't\",\n",
       "  'start': 276.919,\n",
       "  'duration': 5.081},\n",
       " {'text': 'want to go ahead and use this you can',\n",
       "  'start': 280.639,\n",
       "  'duration': 4.401},\n",
       " {'text': 'also go ahead and use grock. Grock also',\n",
       "  'start': 282.0,\n",
       "  'duration': 6.08},\n",
       " {'text': 'has a specific set of code or you can',\n",
       "  'start': 285.04,\n",
       "  'duration': 5.28},\n",
       " {'text': 'also go ahead and use OpenAI code in',\n",
       "  'start': 288.08,\n",
       "  'duration': 3.839},\n",
       " {'text': 'order to probably go ahead and start',\n",
       "  'start': 290.32,\n",
       "  'duration': 3.12},\n",
       " {'text': 'working and developing geni', 'start': 291.919, 'duration': 3.761},\n",
       " {'text': 'applications. Okay. Now this is one of',\n",
       "  'start': 293.44,\n",
       "  'duration': 5.28},\n",
       " {'text': 'the thing. Okay. Now the next two topics',\n",
       "  'start': 295.68,\n",
       "  'duration': 4.4},\n",
       " {'text': 'that we are specifically going to',\n",
       "  'start': 298.72,\n",
       "  'duration': 3.44},\n",
       " {'text': 'discuss about is something called as AI',\n",
       "  'start': 300.08,\n",
       "  'duration': 4.52},\n",
       " {'text': 'agents and agentic AI. And this is super',\n",
       "  'start': 302.16,\n",
       "  'duration': 4.96},\n",
       " {'text': 'important right now because the thing',\n",
       "  'start': 304.6,\n",
       "  'duration': 4.52},\n",
       " {'text': 'that we work on right agentic AI',\n",
       "  'start': 307.12,\n",
       "  'duration': 4.079},\n",
       " {'text': 'application it is trending in every',\n",
       "  'start': 309.12,\n",
       "  'duration': 4.32},\n",
       " {'text': 'field. people are thinking that how they',\n",
       "  'start': 311.199,\n",
       "  'duration': 5.121},\n",
       " {'text': 'can automate the entire complex task the',\n",
       "  'start': 313.44,\n",
       "  'duration': 5.039},\n",
       " {'text': 'entire workflow with the help of agent',\n",
       "  'start': 316.32,\n",
       "  'duration': 4.159},\n",
       " {'text': 'application and obviously bring human',\n",
       "  'start': 318.479,\n",
       "  'duration': 4.401},\n",
       " {'text': 'feedback in between them. Okay. Now',\n",
       "  'start': 320.479,\n",
       "  'duration': 3.921},\n",
       " {'text': \"let's go ahead and discuss about this\",\n",
       "  'start': 322.88,\n",
       "  'duration': 3.52},\n",
       " {'text': 'and I hope I have already made a video',\n",
       "  'start': 324.4,\n",
       "  'duration': 3.359},\n",
       " {'text': 'related to generative way. I have',\n",
       "  'start': 326.4,\n",
       "  'duration': 3.28},\n",
       " {'text': 'developed so many different videos from',\n",
       "  'start': 327.759,\n",
       "  'duration': 3.44},\n",
       " {'text': 'lang chain to lang graph you can',\n",
       "  'start': 329.68,\n",
       "  'duration': 3.48},\n",
       " {'text': 'definitely go ahead and watch.',\n",
       "  'start': 331.199,\n",
       "  'duration': 4.241},\n",
       " {'text': \"Okay. Now let's go ahead and discuss\",\n",
       "  'start': 333.16,\n",
       "  'duration': 3.92},\n",
       " {'text': 'about the second thing which is nothing',\n",
       "  'start': 335.44,\n",
       "  'duration': 4.4},\n",
       " {'text': \"but the second category that we're going\",\n",
       "  'start': 337.08,\n",
       "  'duration': 5.6},\n",
       " {'text': 'to focus on is AI', 'start': 339.84, 'duration': 6.12},\n",
       " {'text': 'agents versus agentic', 'start': 342.68, 'duration': 6.959},\n",
       " {'text': 'AI versus agentic', 'start': 345.96, 'duration': 8.36},\n",
       " {'text': 'AI. Now people do think that AI agents',\n",
       "  'start': 349.639,\n",
       "  'duration': 7.321},\n",
       " {'text': 'and agentic AI one and the same but it',\n",
       "  'start': 354.32,\n",
       "  'duration': 6.319},\n",
       " {'text': 'is not like that. Okay. So here just',\n",
       "  'start': 356.96,\n",
       "  'duration': 6.0},\n",
       " {'text': 'please focus on for the next 10 minutes',\n",
       "  'start': 360.639,\n",
       "  'duration': 3.921},\n",
       " {'text': \"because I'm going to explain each and\",\n",
       "  'start': 362.96,\n",
       "  'duration': 3.359},\n",
       " {'text': 'everything that you really need to',\n",
       "  'start': 364.56,\n",
       "  'duration': 3.44},\n",
       " {'text': \"understand and that is how you'll be\",\n",
       "  'start': 366.319,\n",
       "  'duration': 3.201},\n",
       " {'text': 'able to understand between what is the',\n",
       "  'start': 368.0,\n",
       "  'duration': 3.36},\n",
       " {'text': 'basic difference between AI agents and',\n",
       "  'start': 369.52,\n",
       "  'duration': 5.44},\n",
       " {'text': \"agent AI. Okay. Now let's say that I\",\n",
       "  'start': 371.36,\n",
       "  'duration': 6.0},\n",
       " {'text': \"have some kind of LLMs. Okay. So let's\",\n",
       "  'start': 374.96,\n",
       "  'duration': 5.6},\n",
       " {'text': 'say and at all these places LLM is the',\n",
       "  'start': 377.36,\n",
       "  'duration': 5.279},\n",
       " {'text': 'most important thing right because LLM',\n",
       "  'start': 380.56,\n",
       "  'duration': 4.8},\n",
       " {'text': 'is something that will be acting like an',\n",
       "  'start': 382.639,\n",
       "  'duration': 4.641},\n",
       " {'text': 'AI agent. It can act like an AI agent.',\n",
       "  'start': 385.36,\n",
       "  'duration': 4.0},\n",
       " {'text': 'it can also work in an agentic AI',\n",
       "  'start': 387.28,\n",
       "  'duration': 4.0},\n",
       " {'text': 'application. Okay. And it will it will',\n",
       "  'start': 389.36,\n",
       "  'duration': 4.8},\n",
       " {'text': 'be very important how this AI agents is',\n",
       "  'start': 391.28,\n",
       "  'duration': 5.199},\n",
       " {'text': 'different when compared to the LLM also.',\n",
       "  'start': 394.16,\n",
       "  'duration': 4.96},\n",
       " {'text': \"Okay. So let's say that I have a\",\n",
       "  'start': 396.479,\n",
       "  'duration': 5.041},\n",
       " {'text': 'specific LLM. Okay. And now this LLM can',\n",
       "  'start': 399.12,\n",
       "  'duration': 4.4},\n",
       " {'text': \"be any model. Okay. Let's let's consider\",\n",
       "  'start': 401.52,\n",
       "  'duration': 4.64},\n",
       " {'text': 'that it is it is some model that we are',\n",
       "  'start': 403.52,\n",
       "  'duration': 4.56},\n",
       " {'text': 'going to use from graph. It can be lama',\n",
       "  'start': 406.16,\n",
       "  'duration': 4.24},\n",
       " {'text': '3. We are using this specific model.',\n",
       "  'start': 408.08,\n",
       "  'duration': 5.36},\n",
       " {'text': 'Okay. Now you know that all these LLM or',\n",
       "  'start': 410.4,\n",
       "  'duration': 5.12},\n",
       " {'text': \"LM models they're trained with some\",\n",
       "  'start': 413.44,\n",
       "  'duration': 5.68},\n",
       " {'text': \"specific past data okay they don't have\",\n",
       "  'start': 415.52,\n",
       "  'duration': 5.32},\n",
       " {'text': \"like let's say if I ask this particular\",\n",
       "  'start': 419.12,\n",
       "  'duration': 5.199},\n",
       " {'text': 'LLM hey what is the news for today or',\n",
       "  'start': 420.84,\n",
       "  'duration': 6.68},\n",
       " {'text': 'hey or who won this particular IPL match',\n",
       "  'start': 424.319,\n",
       "  'duration': 5.28},\n",
       " {'text': \"between this and this like let's say\",\n",
       "  'start': 427.52,\n",
       "  'duration': 4.119},\n",
       " {'text': 'Bangalore is going to happen have some',\n",
       "  'start': 429.599,\n",
       "  'duration': 4.801},\n",
       " {'text': 'matches tomorrow or today if it has',\n",
       "  'start': 431.639,\n",
       "  'duration': 5.321},\n",
       " {'text': 'right and LLM will not know the result',\n",
       "  'start': 434.4,\n",
       "  'duration': 4.0},\n",
       " {'text': \"because it's not connected to the\",\n",
       "  'start': 436.96,\n",
       "  'duration': 3.44},\n",
       " {'text': 'internet okay so in that kind of',\n",
       "  'start': 438.4,\n",
       "  'duration': 3.84},\n",
       " {'text': 'scenario Whenever I ask this particular',\n",
       "  'start': 440.4,\n",
       "  'duration': 3.6},\n",
       " {'text': 'question, the LLM will not be able to',\n",
       "  'start': 442.24,\n",
       "  'duration': 4.959},\n",
       " {'text': 'give an output to us. Okay, obviously it',\n",
       "  'start': 444.0,\n",
       "  'duration': 4.72},\n",
       " {'text': 'will not be able to give because it does',\n",
       "  'start': 447.199,\n",
       "  'duration': 4.241},\n",
       " {'text': 'not have that specific information. Now,',\n",
       "  'start': 448.72,\n",
       "  'duration': 5.52},\n",
       " {'text': 'this is one major disadvantage of LLM,',\n",
       "  'start': 451.44,\n",
       "  'duration': 5.28},\n",
       " {'text': 'right? Yes, LLM will be able to generate',\n",
       "  'start': 454.24,\n",
       "  'duration': 4.079},\n",
       " {'text': 'new content. These models will be able',\n",
       "  'start': 456.72,\n",
       "  'duration': 3.28},\n",
       " {'text': 'to generate the new content. But what',\n",
       "  'start': 458.319,\n",
       "  'duration': 3.521},\n",
       " {'text': 'about the current information? Okay, it',\n",
       "  'start': 460.0,\n",
       "  'duration': 4.16},\n",
       " {'text': 'will not be able to give you, right?',\n",
       "  'start': 461.84,\n",
       "  'duration': 4.32},\n",
       " {'text': \"Let's say that I'm going to ask some\",\n",
       "  'start': 464.16,\n",
       "  'duration': 4.319},\n",
       " {'text': 'specific information of a company.',\n",
       "  'start': 466.16,\n",
       "  'duration': 4.24},\n",
       " {'text': 'Obviously this LLM will not be trained',\n",
       "  'start': 468.479,\n",
       "  'duration': 3.681},\n",
       " {'text': 'with that company data because the',\n",
       "  'start': 470.4,\n",
       "  'duration': 3.359},\n",
       " {'text': 'company data will be private to that',\n",
       "  'start': 472.16,\n",
       "  'duration': 4.0},\n",
       " {'text': 'company itself. Right? So that way also',\n",
       "  'start': 473.759,\n",
       "  'duration': 4.081},\n",
       " {'text': 'that LLM will not be able to give you',\n",
       "  'start': 476.16,\n",
       "  'duration': 3.599},\n",
       " {'text': 'that unless and until it is connected to',\n",
       "  'start': 477.84,\n",
       "  'duration': 3.68},\n",
       " {'text': 'some kind of external database or',\n",
       "  'start': 479.759,\n",
       "  'duration': 4.12},\n",
       " {'text': 'external data source. This is just one',\n",
       "  'start': 481.52,\n",
       "  'duration': 4.64},\n",
       " {'text': 'example now what is basically happening',\n",
       "  'start': 483.879,\n",
       "  'duration': 3.88},\n",
       " {'text': 'is that as soon as I asked a question',\n",
       "  'start': 486.16,\n",
       "  'duration': 3.52},\n",
       " {'text': 'hey who won this particular match within',\n",
       "  'start': 487.759,\n",
       "  'duration': 5.44},\n",
       " {'text': 'RCB or any other place any other um any',\n",
       "  'start': 489.68,\n",
       "  'duration': 5.84},\n",
       " {'text': 'other team that happened today it will',\n",
       "  'start': 493.199,\n",
       "  'duration': 4.56},\n",
       " {'text': 'not be able to give you the output. So',\n",
       "  'start': 495.52,\n",
       "  'duration': 3.84},\n",
       " {'text': 'what it will be dependent on it will be',\n",
       "  'start': 497.759,\n",
       "  'duration': 4.401},\n",
       " {'text': 'dependent on the third party source.',\n",
       "  'start': 499.36,\n",
       "  'duration': 4.16},\n",
       " {'text': \"Let's say there is one third party\",\n",
       "  'start': 502.16,\n",
       "  'duration': 2.96},\n",
       " {'text': 'source I will consider in this', 'start': 503.52, 'duration': 3.6},\n",
       " {'text': 'particular scenario. I will just go',\n",
       "  'start': 505.12,\n",
       "  'duration': 4.24},\n",
       " {'text': 'ahead and connect it to some kind of',\n",
       "  'start': 507.12,\n",
       "  'duration': 4.72},\n",
       " {'text': \"database. Okay. Let's say one of the\",\n",
       "  'start': 509.36,\n",
       "  'duration': 5.28},\n",
       " {'text': 'data source is something called as taby.',\n",
       "  'start': 511.84,\n",
       "  'duration': 4.879},\n",
       " {'text': 'I will go ahead and write tabi. So if',\n",
       "  'start': 514.64,\n",
       "  'duration': 3.92},\n",
       " {'text': \"you don't know about tabi it provides\",\n",
       "  'start': 516.719,\n",
       "  'duration': 4.161},\n",
       " {'text': 'you some kind of internet search. Okay.',\n",
       "  'start': 518.56,\n",
       "  'duration': 4.399},\n",
       " {'text': 'It you can use that particular API. You',\n",
       "  'start': 520.88,\n",
       "  'duration': 3.92},\n",
       " {'text': 'can write this specific wrapper and you',\n",
       "  'start': 522.959,\n",
       "  'duration': 3.681},\n",
       " {'text': 'can probably go ahead and write this.',\n",
       "  'start': 524.8,\n",
       "  'duration': 5.039},\n",
       " {'text': 'Now the question arises how this llm is',\n",
       "  'start': 526.64,\n",
       "  'duration': 5.84},\n",
       " {'text': 'basically going to call this tavly API.',\n",
       "  'start': 529.839,\n",
       "  'duration': 4.641},\n",
       " {'text': 'Now there is one very important property',\n",
       "  'start': 532.48,\n",
       "  'duration': 3.68},\n",
       " {'text': \"if you're learning lang chain or lang\",\n",
       "  'start': 534.48,\n",
       "  'duration': 4.0},\n",
       " {'text': 'graph any of the specific libraries',\n",
       "  'start': 536.16,\n",
       "  'duration': 3.84},\n",
       " {'text': 'there is a concept of something called',\n",
       "  'start': 538.48,\n",
       "  'duration': 4.52},\n",
       " {'text': 'as tool call. Tool', 'start': 540.0, 'duration': 6.64},\n",
       " {'text': 'call. Okay tool call. Now what is this',\n",
       "  'start': 543.0,\n",
       "  'duration': 5.72},\n",
       " {'text': \"tool call? Let's say that if the LLM is\",\n",
       "  'start': 546.64,\n",
       "  'duration': 4.24},\n",
       " {'text': 'not able to provide the response for',\n",
       "  'start': 548.72,\n",
       "  'duration': 4.64},\n",
       " {'text': 'this particular input, it will keep on',\n",
       "  'start': 550.88,\n",
       "  'duration': 4.959},\n",
       " {'text': 'looking for external things that will be',\n",
       "  'start': 553.36,\n",
       "  'duration': 4.64},\n",
       " {'text': 'able to handle this particular input.',\n",
       "  'start': 555.839,\n",
       "  'duration': 4.321},\n",
       " {'text': 'Now in this particular case when I ask',\n",
       "  'start': 558.0,\n",
       "  'duration': 4.08},\n",
       " {'text': 'the input saying that hey what is the',\n",
       "  'start': 560.16,\n",
       "  'duration': 4.56},\n",
       " {'text': 'current news? What is the current news',\n",
       "  'start': 562.08,\n",
       "  'duration': 4.72},\n",
       " {'text': \"for this specific date that is today's\",\n",
       "  'start': 564.72,\n",
       "  'duration': 4.08},\n",
       " {'text': 'date? The LLM will not be able to give',\n",
       "  'start': 566.8,\n",
       "  'duration': 4.64},\n",
       " {'text': 'the answer. So the LLM will look for',\n",
       "  'start': 568.8,\n",
       "  'duration': 4.36},\n",
       " {'text': 'whether it is connected to any', 'start': 571.44, 'duration': 5.6},\n",
       " {'text': 'third-party APIs, third party APIs or',\n",
       "  'start': 573.16,\n",
       "  'duration': 5.88},\n",
       " {'text': 'data source from which I will be able to',\n",
       "  'start': 577.04,\n",
       "  'duration': 4.64},\n",
       " {'text': 'get this kind of information. So that is',\n",
       "  'start': 579.04,\n",
       "  'duration': 5.28},\n",
       " {'text': 'where it will be making the specific',\n",
       "  'start': 581.68,\n",
       "  'duration': 5.599},\n",
       " {'text': 'tool call. Okay, it will be making the',\n",
       "  'start': 584.32,\n",
       "  'duration': 4.639},\n",
       " {'text': 'specific tool call. Now this tool call',\n",
       "  'start': 587.279,\n",
       "  'duration': 3.12},\n",
       " {'text': 'will be something like this. The tool',\n",
       "  'start': 588.959,\n",
       "  'duration': 3.44},\n",
       " {'text': 'call will be made and based on this I',\n",
       "  'start': 590.399,\n",
       "  'duration': 5.281},\n",
       " {'text': \"will be getting a response. Okay, I'll\",\n",
       "  'start': 592.399,\n",
       "  'duration': 5.681},\n",
       " {'text': 'be getting a response. Now the as soon',\n",
       "  'start': 595.68,\n",
       "  'duration': 5.839},\n",
       " {'text': 'as the LLM made this tool call the it',\n",
       "  'start': 598.08,\n",
       "  'duration': 5.28},\n",
       " {'text': 'got this specific response. So this is',\n",
       "  'start': 601.519,\n",
       "  'duration': 4.521},\n",
       " {'text': 'my request and this is my response.',\n",
       "  'start': 603.36,\n",
       "  'duration': 5.919},\n",
       " {'text': 'Okay, this is my response and as soon as',\n",
       "  'start': 606.04,\n",
       "  'duration': 5.56},\n",
       " {'text': 'I got the response the LLM is smart',\n",
       "  'start': 609.279,\n",
       "  'duration': 4.401},\n",
       " {'text': 'enough to finally summarize that', 'start': 611.6, 'duration': 4.4},\n",
       " {'text': 'particular output uh that response and',\n",
       "  'start': 613.68,\n",
       "  'duration': 4.24},\n",
       " {'text': \"give you the output and this is what I'm\",\n",
       "  'start': 616.0,\n",
       "  'duration': 4.56},\n",
       " {'text': 'actually looking for. Okay.', 'start': 617.92, 'duration': 4.919},\n",
       " {'text': 'Now you need to really understand over',\n",
       "  'start': 620.56,\n",
       "  'duration': 5.76},\n",
       " {'text': 'here the kind of task that is happening',\n",
       "  'start': 622.839,\n",
       "  'duration': 5.721},\n",
       " {'text': \"right a request is going I'm getting the\",\n",
       "  'start': 626.32,\n",
       "  'duration': 4.12},\n",
       " {'text': \"information I'm getting giving back the\",\n",
       "  'start': 628.56,\n",
       "  'duration': 4.64},\n",
       " {'text': 'response this is basically happening by',\n",
       "  'start': 630.44,\n",
       "  'duration': 6.36},\n",
       " {'text': 'an AI agent just a single AI agent I can',\n",
       "  'start': 633.2,\n",
       "  'duration': 6.8},\n",
       " {'text': 'consider this as an AI agent okay here',\n",
       "  'start': 636.8,\n",
       "  'duration': 5.76},\n",
       " {'text': 'my main aim is that I have asked an',\n",
       "  'start': 640.0,\n",
       "  'duration': 4.399},\n",
       " {'text': 'input saying that hey give me the some',\n",
       "  'start': 642.56,\n",
       "  'duration': 5.279},\n",
       " {'text': 'current information about today AI news',\n",
       "  'start': 644.399,\n",
       "  'duration': 5.761},\n",
       " {'text': 'I really want to see for this particular',\n",
       "  'start': 647.839,\n",
       "  'duration': 4.401},\n",
       " {'text': 'date AI news which my LLM was not able',\n",
       "  'start': 650.16,\n",
       "  'duration': 4.08},\n",
       " {'text': 'to do it. So what it has done is that',\n",
       "  'start': 652.24,\n",
       "  'duration': 4.08},\n",
       " {'text': 'the LLM is smart enough to understand',\n",
       "  'start': 654.24,\n",
       "  'duration': 4.48},\n",
       " {'text': 'which tool to probably call and based on',\n",
       "  'start': 656.32,\n",
       "  'duration': 3.92},\n",
       " {'text': 'this tool call functional it is calling',\n",
       "  'start': 658.72,\n",
       "  'duration': 3.6},\n",
       " {'text': 'this and it is getting the response. So',\n",
       "  'start': 660.24,\n",
       "  'duration': 5.12},\n",
       " {'text': 'this is a specific task okay and this',\n",
       "  'start': 662.32,\n",
       "  'duration': 5.44},\n",
       " {'text': 'task is basically solved by this tavly',\n",
       "  'start': 665.36,\n",
       "  'duration': 4.32},\n",
       " {'text': 'okay tavly which is responsible for the',\n",
       "  'start': 667.76,\n",
       "  'duration': 5.12},\n",
       " {'text': 'internet search. So this task can be',\n",
       "  'start': 669.68,\n",
       "  'duration': 5.52},\n",
       " {'text': 'considered as an AI agent. Okay, for a',\n",
       "  'start': 672.88,\n",
       "  'duration': 4.399},\n",
       " {'text': 'specific task we have defined this.',\n",
       "  'start': 675.2,\n",
       "  'duration': 4.72},\n",
       " {'text': 'Okay, very simple definition. Okay, so',\n",
       "  'start': 677.279,\n",
       "  'duration': 4.321},\n",
       " {'text': 'for a specific task we are able to',\n",
       "  'start': 679.92,\n",
       "  'duration': 3.039},\n",
       " {'text': 'probably go ahead and call this and we',\n",
       "  'start': 681.6,\n",
       "  'duration': 2.96},\n",
       " {'text': 'are getting the response. Now the',\n",
       "  'start': 682.959,\n",
       "  'duration': 4.521},\n",
       " {'text': 'question rises, now the question',\n",
       "  'start': 684.56,\n",
       "  'duration': 6.48},\n",
       " {'text': 'rises then what is agentic AI? AI agents',\n",
       "  'start': 687.48,\n",
       "  'duration': 5.64},\n",
       " {'text': 'have understood okay fine for a specific',\n",
       "  'start': 691.04,\n",
       "  'duration': 4.4},\n",
       " {'text': \"task I'm calling something from the LLM,\",\n",
       "  'start': 693.12,\n",
       "  'duration': 4.399},\n",
       " {'text': 'right? The LM is responsible for making',\n",
       "  'start': 695.44,\n",
       "  'duration': 3.68},\n",
       " {'text': 'that tool call and getting the output',\n",
       "  'start': 697.519,\n",
       "  'duration': 3.281},\n",
       " {'text': 'and summarizing the output and giving it',\n",
       "  'start': 699.12,\n",
       "  'duration': 3.36},\n",
       " {'text': 'over here. Here also we can add the',\n",
       "  'start': 700.8,\n",
       "  'duration': 4.159},\n",
       " {'text': 'prompt. Here also once I get the',\n",
       "  'start': 702.48,\n",
       "  'duration': 4.799},\n",
       " {'text': 'response I can add the prompt and based',\n",
       "  'start': 704.959,\n",
       "  'duration': 4.161},\n",
       " {'text': 'on that I can summarize the output. I',\n",
       "  'start': 707.279,\n",
       "  'duration': 3.921},\n",
       " {'text': 'can do that. Okay. But this is only for',\n",
       "  'start': 709.12,\n",
       "  'duration': 4.719},\n",
       " {'text': 'one kind of task. Now if I talk about',\n",
       "  'start': 711.2,\n",
       "  'duration': 5.199},\n",
       " {'text': 'agentic AI okay and for discussing about',\n",
       "  'start': 713.839,\n",
       "  'duration': 4.161},\n",
       " {'text': \"the agentic AI application let's\",\n",
       "  'start': 716.399,\n",
       "  'duration': 4.241},\n",
       " {'text': \"consider that let's consider that I have\",\n",
       "  'start': 718.0,\n",
       "  'duration': 5.839},\n",
       " {'text': 'a task and this task is nothing but',\n",
       "  'start': 720.64,\n",
       "  'duration': 5.28},\n",
       " {'text': \"let's consider I want to probably\",\n",
       "  'start': 723.839,\n",
       "  'duration': 4.641},\n",
       " {'text': 'convert a YT video that I really want to',\n",
       "  'start': 725.92,\n",
       "  'duration': 4.52},\n",
       " {'text': 'upload to a', 'start': 728.48, 'duration': 3.64},\n",
       " {'text': 'blog', 'start': 730.44, 'duration': 6.519},\n",
       " {'text': 'okay to a blog and now to convert a YT',\n",
       "  'start': 732.12,\n",
       "  'duration': 7.959},\n",
       " {'text': \"video YouTube video into a blog let's\",\n",
       "  'start': 736.959,\n",
       "  'duration': 5.201},\n",
       " {'text': 'say that I have been uploading so many',\n",
       "  'start': 740.079,\n",
       "  'duration': 4.241},\n",
       " {'text': 'videos. Just imagine if I just create an',\n",
       "  'start': 742.16,\n",
       "  'duration': 4.56},\n",
       " {'text': 'agenti system which takes my YouTube',\n",
       "  'start': 744.32,\n",
       "  'duration': 4.48},\n",
       " {'text': 'video and convert that into a blog and',\n",
       "  'start': 746.72,\n",
       "  'duration': 4.32},\n",
       " {'text': 'publish it in my website. Would it will',\n",
       "  'start': 748.8,\n",
       "  'duration': 4.24},\n",
       " {'text': 'that not be good? It will definitely be',\n",
       "  'start': 751.04,\n",
       "  'duration': 4.72},\n",
       " {'text': 'good. Right now here if I probably see I',\n",
       "  'start': 753.04,\n",
       "  'duration': 4.64},\n",
       " {'text': 'can divide this into multiple subtask.',\n",
       "  'start': 755.76,\n",
       "  'duration': 4.639},\n",
       " {'text': 'First of all I will take this YT video.',\n",
       "  'start': 757.68,\n",
       "  'duration': 4.8},\n",
       " {'text': 'I will convert I will take the',\n",
       "  'start': 760.399,\n",
       "  'duration': 5.361},\n",
       " {'text': 'transcript from the YT video. Transcript',\n",
       "  'start': 762.48,\n",
       "  'duration': 6.159},\n",
       " {'text': 'from the YT video. Okay. After', 'start': 765.76, 'duration': 5.28},\n",
       " {'text': 'considering the transcript from this my',\n",
       "  'start': 768.639,\n",
       "  'duration': 5.161},\n",
       " {'text': 'second task will be creating', 'start': 771.04, 'duration': 6.96},\n",
       " {'text': 'title. Creating title. Okay. Third it',\n",
       "  'start': 773.8,\n",
       "  'duration': 7.0},\n",
       " {'text': 'can be creating', 'start': 778.0, 'duration': 2.8},\n",
       " {'text': 'description. Okay. So this will be my',\n",
       "  'start': 780.839,\n",
       "  'duration': 4.401},\n",
       " {'text': 'third task creating', 'start': 782.959, 'duration': 4.88},\n",
       " {'text': 'description and my fourth task will be',\n",
       "  'start': 785.24,\n",
       "  'duration': 3.92},\n",
       " {'text': 'writing the', 'start': 787.839, 'duration': 3.761},\n",
       " {'text': \"conclusion. Let's say so I've defined\",\n",
       "  'start': 789.16,\n",
       "  'duration': 5.799},\n",
       " {'text': 'this task into four different task right',\n",
       "  'start': 791.6,\n",
       "  'duration': 5.28},\n",
       " {'text': 'four different tasks. Now for the same',\n",
       "  'start': 794.959,\n",
       "  'duration': 6.201},\n",
       " {'text': \"task, don't you think converting a\",\n",
       "  'start': 796.88,\n",
       "  'duration': 8.56},\n",
       " {'text': 'YT YT video into transcript, I can',\n",
       "  'start': 801.16,\n",
       "  'duration': 7.96},\n",
       " {'text': 'create one AI agent. Then similarly for',\n",
       "  'start': 805.44,\n",
       "  'duration': 6.399},\n",
       " {'text': 'my second AI agent, I can basically take',\n",
       "  'start': 809.12,\n",
       "  'duration': 4.279},\n",
       " {'text': 'this transcript', 'start': 811.839, 'duration': 4.8},\n",
       " {'text': 'and this AI agent should be able to give',\n",
       "  'start': 813.399,\n",
       "  'duration': 6.841},\n",
       " {'text': 'me the title. Yeah. Yeah. And just to',\n",
       "  'start': 816.639,\n",
       "  'duration': 6.0},\n",
       " {'text': 'show you how these things will happen,',\n",
       "  'start': 820.24,\n",
       "  'duration': 5.599},\n",
       " {'text': \"don't you think I can just go ahead see\",\n",
       "  'start': 822.639,\n",
       "  'duration': 5.281},\n",
       " {'text': 'this? Okay, see this magic. Okay. So, so',\n",
       "  'start': 825.839,\n",
       "  'duration': 3.921},\n",
       " {'text': 'what what I will be doing is that my',\n",
       "  'start': 827.92,\n",
       "  'duration': 4.32},\n",
       " {'text': 'first task will be that this AI agent',\n",
       "  'start': 829.76,\n",
       "  'duration': 4.8},\n",
       " {'text': 'will be responsible in getting me the',\n",
       "  'start': 832.24,\n",
       "  'duration': 4.24},\n",
       " {'text': 'transcript from my YouTube video. Okay.',\n",
       "  'start': 834.56,\n",
       "  'duration': 4.48},\n",
       " {'text': 'This AI agent will be responsible for',\n",
       "  'start': 836.48,\n",
       "  'duration': 4.64},\n",
       " {'text': 'creating the title from the transcript',\n",
       "  'start': 839.04,\n",
       "  'duration': 5.44},\n",
       " {'text': 'that I get. Okay. Then my next agent',\n",
       "  'start': 841.12,\n",
       "  'duration': 5.68},\n",
       " {'text': 'over here which will be parallelly will',\n",
       "  'start': 844.48,\n",
       "  'duration': 3.08},\n",
       " {'text': 'be', 'start': 846.8, 'duration': 3.039},\n",
       " {'text': 'responsible to probably create the',\n",
       "  'start': 847.56,\n",
       "  'duration': 3.839},\n",
       " {'text': 'description from this particular',\n",
       "  'start': 849.839,\n",
       "  'duration': 4.721},\n",
       " {'text': \"transcript. Yeah. And finally, don't you\",\n",
       "  'start': 851.399,\n",
       "  'duration': 6.641},\n",
       " {'text': 'think I can have one more one', 'start': 854.56, 'duration': 8.16},\n",
       " {'text': 'more AI agent which will be responsible',\n",
       "  'start': 858.04,\n",
       "  'duration': 8.4},\n",
       " {'text': 'in creating the conclusion. Right? Now',\n",
       "  'start': 862.72,\n",
       "  'duration': 7.76},\n",
       " {'text': \"here this is my AI agent one. Let's\",\n",
       "  'start': 866.44,\n",
       "  'duration': 7.24},\n",
       " {'text': 'consider this. Okay. So this is my AI',\n",
       "  'start': 870.48,\n",
       "  'duration': 5.08},\n",
       " {'text': 'agent', 'start': 873.68, 'duration': 6.04},\n",
       " {'text': 'one. This is my AI agent', 'start': 875.56, 'duration': 9.32},\n",
       " {'text': '2. This is my AI agent three. And this',\n",
       "  'start': 879.72,\n",
       "  'duration': 7.28},\n",
       " {'text': 'is my AI agent', 'start': 884.88, 'duration': 7.68},\n",
       " {'text': '4. Each and every agent can use LLM. It',\n",
       "  'start': 887.0,\n",
       "  'duration': 8.0},\n",
       " {'text': 'can use', 'start': 892.56, 'duration': 7.44},\n",
       " {'text': 'prompt to perform its task. Each each',\n",
       "  'start': 895.0,\n",
       "  'duration': 7.959},\n",
       " {'text': 'here it can or it cannot it is not',\n",
       "  'start': 900.0,\n",
       "  'duration': 5.199},\n",
       " {'text': 'composite it needs to use all the LLM',\n",
       "  'start': 902.959,\n",
       "  'duration': 4.161},\n",
       " {'text': 'but since we are working with respect to',\n",
       "  'start': 905.199,\n",
       "  'duration': 4.64},\n",
       " {'text': 'text related things then obviously we',\n",
       "  'start': 907.12,\n",
       "  'duration': 5.68},\n",
       " {'text': 'can use LLM okay for now this is just',\n",
       "  'start': 909.839,\n",
       "  'duration': 5.36},\n",
       " {'text': 'like a one kind of workflow so this',\n",
       "  'start': 912.8,\n",
       "  'duration': 4.08},\n",
       " {'text': 'workflow goes on like this right so',\n",
       "  'start': 915.199,\n",
       "  'duration': 5.0},\n",
       " {'text': 'first of all I give my YT video',\n",
       "  'start': 916.88,\n",
       "  'duration': 6.959},\n",
       " {'text': 'URL YT video URL then this agent is',\n",
       "  'start': 920.199,\n",
       "  'duration': 6.041},\n",
       " {'text': 'responsible in taking from this and',\n",
       "  'start': 923.839,\n",
       "  'duration': 4.601},\n",
       " {'text': 'giving the output a', 'start': 926.24, 'duration': 6.399},\n",
       " {'text': 'transcript. Now this transcript is sent',\n",
       "  'start': 928.44,\n",
       "  'duration': 8.6},\n",
       " {'text': 'to all the agents and finally we can',\n",
       "  'start': 932.639,\n",
       "  'duration': 7.161},\n",
       " {'text': 'combine all these', 'start': 937.04, 'duration': 6.28},\n",
       " {'text': 'outputs and give my final', 'start': 939.8, 'duration': 6.68},\n",
       " {'text': 'blog. Right? So what does this basically',\n",
       "  'start': 943.32,\n",
       "  'duration': 6.519},\n",
       " {'text': 'mean? Before an AI agent only used to do',\n",
       "  'start': 946.48,\n",
       "  'duration': 6.56},\n",
       " {'text': 'one task in an agentic AI system. So',\n",
       "  'start': 949.839,\n",
       "  'duration': 6.881},\n",
       " {'text': 'this is my entire complex workflow with',\n",
       "  'start': 953.04,\n",
       "  'duration': 7.52},\n",
       " {'text': 'respect to my agentic AI system and this',\n",
       "  'start': 956.72,\n",
       "  'duration': 7.96},\n",
       " {'text': 'is performing this entire task together.',\n",
       "  'start': 960.56,\n",
       "  'duration': 7.04},\n",
       " {'text': 'Here every agent is communicating with',\n",
       "  'start': 964.68,\n",
       "  'duration': 5.959},\n",
       " {'text': 'each other. Right? I can add one more',\n",
       "  'start': 967.6,\n",
       "  'duration': 5.799},\n",
       " {'text': 'thing over here. I can add human',\n",
       "  'start': 970.639,\n",
       "  'duration': 5.721},\n",
       " {'text': 'feedback. Human feedback also over',\n",
       "  'start': 973.399,\n",
       "  'duration': 5.321},\n",
       " {'text': 'here. So here what is basically',\n",
       "  'start': 976.36,\n",
       "  'duration': 4.76},\n",
       " {'text': 'happening? AI agents are communicating',\n",
       "  'start': 978.72,\n",
       "  'duration': 4.0},\n",
       " {'text': 'with each other.', 'start': 981.12, 'duration': 4.719},\n",
       " {'text': 'Right. I can also make sure to probably',\n",
       "  'start': 982.72,\n",
       "  'duration': 5.039},\n",
       " {'text': \"before this AI agent, let's say this\",\n",
       "  'start': 985.839,\n",
       "  'duration': 3.521},\n",
       " {'text': 'agent is responsible in probably',\n",
       "  'start': 987.759,\n",
       "  'duration': 3.921},\n",
       " {'text': 'creating a description. For creating a',\n",
       "  'start': 989.36,\n",
       "  'duration': 4.24},\n",
       " {'text': 'description, it also wants the title. So',\n",
       "  'start': 991.68,\n",
       "  'duration': 4.48},\n",
       " {'text': 'it will just go ahead this AI agent 2',\n",
       "  'start': 993.6,\n",
       "  'duration': 4.4},\n",
       " {'text': 'whatever output it is creating for the',\n",
       "  'start': 996.16,\n",
       "  'duration': 4.08},\n",
       " {'text': 'title, it will give it to the agent 3.',\n",
       "  'start': 998.0,\n",
       "  'duration': 4.079},\n",
       " {'text': 'And this will take that information and',\n",
       "  'start': 1000.24,\n",
       "  'duration': 4.159},\n",
       " {'text': \"do this. So internally you'll be able to\",\n",
       "  'start': 1002.079,\n",
       "  'duration': 4.56},\n",
       " {'text': 'see we can also make this agent',\n",
       "  'start': 1004.399,\n",
       "  'duration': 5.761},\n",
       " {'text': 'communicate with each other to solve a',\n",
       "  'start': 1006.639,\n",
       "  'duration': 6.801},\n",
       " {'text': 'complex workflow and finally achieve a',\n",
       "  'start': 1010.16,\n",
       "  'duration': 6.4},\n",
       " {'text': 'goal. Right? So just to understand what',\n",
       "  'start': 1013.44,\n",
       "  'duration': 4.399},\n",
       " {'text': 'is the difference between AI agents',\n",
       "  'start': 1016.56,\n",
       "  'duration': 3.68},\n",
       " {'text': 'versus agentic AI here AI agent is doing',\n",
       "  'start': 1017.839,\n",
       "  'duration': 5.521},\n",
       " {'text': 'only one task. In an agentic AI system',\n",
       "  'start': 1020.24,\n",
       "  'duration': 5.36},\n",
       " {'text': 'this AI agents will be collaborating',\n",
       "  'start': 1023.36,\n",
       "  'duration': 3.599},\n",
       " {'text': 'with each other. This is really',\n",
       "  'start': 1025.6,\n",
       "  'duration': 3.959},\n",
       " {'text': 'important.', 'start': 1026.959, 'duration': 4.441},\n",
       " {'text': 'Collaborating', 'start': 1029.559, 'duration': 5.041},\n",
       " {'text': 'collaborating with each', 'start': 1031.4, 'duration': 6.559},\n",
       " {'text': 'other to solve a', 'start': 1034.6, 'duration': 7.04},\n",
       " {'text': 'goal. This is really really important to',\n",
       "  'start': 1037.959,\n",
       "  'duration': 6.201},\n",
       " {'text': 'understand. So I hope you understood',\n",
       "  'start': 1041.64,\n",
       "  'duration': 4.36},\n",
       " {'text': 'this particular video. I hope you liked',\n",
       "  'start': 1044.16,\n",
       "  'duration': 3.519},\n",
       " {'text': 'this particular video. This was the',\n",
       "  'start': 1046.0,\n",
       "  'duration': 3.52},\n",
       " {'text': 'basic differences between generative AI',\n",
       "  'start': 1047.679,\n",
       "  'duration': 4.641},\n",
       " {'text': 'versus AI agent versus agentic AI. And I',\n",
       "  'start': 1049.52,\n",
       "  'duration': 4.64},\n",
       " {'text': 'hope you are able to understand this.',\n",
       "  'start': 1052.32,\n",
       "  'duration': 4.08},\n",
       " {'text': \"Okay. Similar kind of videos I'm also\",\n",
       "  'start': 1054.16,\n",
       "  'duration': 4.08},\n",
       " {'text': 'going to come up in this specific series',\n",
       "  'start': 1056.4,\n",
       "  'duration': 4.32},\n",
       " {'text': 'so that you get your fundamental rights.',\n",
       "  'start': 1058.24,\n",
       "  'duration': 4.0},\n",
       " {'text': 'I hope you like this particular video.',\n",
       "  'start': 1060.72,\n",
       "  'duration': 2.88},\n",
       " {'text': \"This was it from my side. I'll see you\",\n",
       "  'start': 1062.24,\n",
       "  'duration': 2.72},\n",
       " {'text': 'in the next video. Have a great day.',\n",
       "  'start': 1063.6,\n",
       "  'duration': 5.36},\n",
       " {'text': 'Thank you and all. Take care. Bye-bye.',\n",
       "  'start': 1064.96,\n",
       "  'duration': 4.0}]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fe9095",
   "metadata": {},
   "source": [
    "# Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "e517885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)\n",
    "chunks = splitter.create_documents([transcript])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "5590e3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "af02d024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content=\"Hello all, my name is Krishna and welcome to my YouTube channel. So guys, today in this particular video we are going to discuss about the basic differences between generative AI versus AI agents versus agentic AI. Now this is one of the most trending topics that is currently going on and it is necessary that you need to have your understanding very much clear when you are specifically working in all the specific topics. Okay. So one by one we will try to understand about each and every topics that I have actually mentioned over here. We'll go step by step. Okay. So first thing is that I hope you may be knowing large language models. Okay. You may be knowing about large image models also. Right? So let's say that I'll also go ahead and write large image models. When we talk about large language models or large image model, these models are actually very huge models, right? These are like huge models, bigger models, right? It can be of billions of parameters and they have trained with\"),\n",
       " Document(metadata={}, page_content=\"models or large image model, these models are actually very huge models, right? These are like huge models, bigger models, right? It can be of billions of parameters and they have trained with huge amount of data, right? This data that it is specifically used to train this model is huge. So you may have seen various models like llama 3. You may have been seeing OpenAI models right from GPT4 to GPT4 mini. Many many different models are there. And these models are specifically trained with huge amount of data. And at the end of the day, all these particular models are generating what are they basically doing? They're generating new content, right? Generating new content. Now, when we talk about generating new content, the models can probably generate new images, it can generate new text, it can generate video frames, it can generate anything as such, right? audio it can also generate audio right and it can also generate videos so I've written each and everything about over here right so\"),\n",
       " Document(metadata={}, page_content=\"can generate video frames, it can generate anything as such, right? audio it can also generate audio right and it can also generate videos so I've written each and everything about over here right so here what this LLM is basically doing since it is trained with huge amount of data in short it is basically generating new content whenever we try to give any kind of input right if I say hey please generate a new image related to aentic AI so this LLA model it if it has that multimodel capabilities it will be able to generate that particular image or video whatever specific things we require whenever we talk in this specific way this is something related to generative AI okay so this is something related to generative AI right now when we say hey uh let's go ahead and build a generative AI application wherein we create a chatbot okay and that chatbot should be able to do this specific ch uh task wherein the main aim is generating new content you can definitely do it right so There we\"),\n",
       " Document(metadata={}, page_content=\"application wherein we create a chatbot okay and that chatbot should be able to do this specific ch uh task wherein the main aim is generating new content you can definitely do it right so There we specifically say hey we are specifically working in generative AI applications right here the most important thing is that there's some few properties that everybody should keep in mind right whenever we talk about generative AI application these are specifically reactive okay reactive there is this word that we use which we basically say it as reactive now what does this basically reactive mean right see in order to work with this LLM models right we definitely have to write some kind of prompts okay prompts and based on this particular prompt this LLM model will generate new content this is really important to understand now what does this prompt basically means this prompt is just like some sentence where we specify something and we tell the LLM to behave in that way I may say hey that\"),\n",
       " Document(metadata={}, page_content=\"really important to understand now what does this prompt basically means this prompt is just like some sentence where we specify something and we tell the LLM to behave in that way I may say hey that uh hey please try to uh act as a data scientist and take an interview for me right so I that is a kind of prompt that is a kind of instruction that I'm actually giving to the LLM model right so here the most important thing with respect to the generative AI content uh generative AI application is that obviously you will be having some kind of models LLM models LM models multimodel right along with these models we specifically write prompts right like how this particular LML model should be behaving and that is how it'll go ahead and generate the new content. Okay. So this is with respect to the generative AI applications. Right? Here uh there are lot of different different kind of libraries. There are libraries like langraph right. There are libraries like lang chain which you can\"),\n",
       " Document(metadata={}, page_content=\"to the generative AI applications. Right? Here uh there are lot of different different kind of libraries. There are libraries like langraph right. There are libraries like lang chain which you can specifically use and you can get started with right lang chain. There are different different libraries like let's say llama index. Llama index right? If you don't want to go ahead and use this you can also go ahead and use grock. Grock also has a specific set of code or you can also go ahead and use OpenAI code in order to probably go ahead and start working and developing geni applications. Okay. Now this is one of the thing. Okay. Now the next two topics that we are specifically going to discuss about is something called as AI agents and agentic AI. And this is super important right now because the thing that we work on right agentic AI application it is trending in every field. people are thinking that how they can automate the entire complex task the entire workflow with the help of\"),\n",
       " Document(metadata={}, page_content=\"the thing that we work on right agentic AI application it is trending in every field. people are thinking that how they can automate the entire complex task the entire workflow with the help of agent application and obviously bring human feedback in between them. Okay. Now let's go ahead and discuss about this and I hope I have already made a video related to generative way. I have developed so many different videos from lang chain to lang graph you can definitely go ahead and watch. Okay. Now let's go ahead and discuss about the second thing which is nothing but the second category that we're going to focus on is AI agents versus agentic AI versus agentic AI. Now people do think that AI agents and agentic AI one and the same but it is not like that. Okay. So here just please focus on for the next 10 minutes because I'm going to explain each and everything that you really need to understand and that is how you'll be able to understand between what is the basic difference between AI\"),\n",
       " Document(metadata={}, page_content=\"the next 10 minutes because I'm going to explain each and everything that you really need to understand and that is how you'll be able to understand between what is the basic difference between AI agents and agent AI. Okay. Now let's say that I have some kind of LLMs. Okay. So let's say and at all these places LLM is the most important thing right because LLM is something that will be acting like an AI agent. It can act like an AI agent. it can also work in an agentic AI application. Okay. And it will it will be very important how this AI agents is different when compared to the LLM also. Okay. So let's say that I have a specific LLM. Okay. And now this LLM can be any model. Okay. Let's let's consider that it is it is some model that we are going to use from graph. It can be lama 3. We are using this specific model. Okay. Now you know that all these LLM or LM models they're trained with some specific past data okay they don't have like let's say if I ask this particular LLM hey what\"),\n",
       " Document(metadata={}, page_content=\"using this specific model. Okay. Now you know that all these LLM or LM models they're trained with some specific past data okay they don't have like let's say if I ask this particular LLM hey what is the news for today or hey or who won this particular IPL match between this and this like let's say Bangalore is going to happen have some matches tomorrow or today if it has right and LLM will not know the result because it's not connected to the internet okay so in that kind of scenario Whenever I ask this particular question, the LLM will not be able to give an output to us. Okay, obviously it will not be able to give because it does not have that specific information. Now, this is one major disadvantage of LLM, right? Yes, LLM will be able to generate new content. These models will be able to generate the new content. But what about the current information? Okay, it will not be able to give you, right? Let's say that I'm going to ask some specific information of a company. Obviously\"),\n",
       " Document(metadata={}, page_content=\"to generate the new content. But what about the current information? Okay, it will not be able to give you, right? Let's say that I'm going to ask some specific information of a company. Obviously this LLM will not be trained with that company data because the company data will be private to that company itself. Right? So that way also that LLM will not be able to give you that unless and until it is connected to some kind of external database or external data source. This is just one example now what is basically happening is that as soon as I asked a question hey who won this particular match within RCB or any other place any other um any other team that happened today it will not be able to give you the output. So what it will be dependent on it will be dependent on the third party source. Let's say there is one third party source I will consider in this particular scenario. I will just go ahead and connect it to some kind of database. Okay. Let's say one of the data source is\"),\n",
       " Document(metadata={}, page_content=\"source. Let's say there is one third party source I will consider in this particular scenario. I will just go ahead and connect it to some kind of database. Okay. Let's say one of the data source is something called as taby. I will go ahead and write tabi. So if you don't know about tabi it provides you some kind of internet search. Okay. It you can use that particular API. You can write this specific wrapper and you can probably go ahead and write this. Now the question arises how this llm is basically going to call this tavly API. Now there is one very important property if you're learning lang chain or lang graph any of the specific libraries there is a concept of something called as tool call. Tool call. Okay tool call. Now what is this tool call? Let's say that if the LLM is not able to provide the response for this particular input, it will keep on looking for external things that will be able to handle this particular input. Now in this particular case when I ask the input\"),\n",
       " Document(metadata={}, page_content=\"able to provide the response for this particular input, it will keep on looking for external things that will be able to handle this particular input. Now in this particular case when I ask the input saying that hey what is the current news? What is the current news for this specific date that is today's date? The LLM will not be able to give the answer. So the LLM will look for whether it is connected to any third-party APIs, third party APIs or data source from which I will be able to get this kind of information. So that is where it will be making the specific tool call. Okay, it will be making the specific tool call. Now this tool call will be something like this. The tool call will be made and based on this I will be getting a response. Okay, I'll be getting a response. Now the as soon as the LLM made this tool call the it got this specific response. So this is my request and this is my response. Okay, this is my response and as soon as I got the response the LLM is smart enough\"),\n",
       " Document(metadata={}, page_content=\"as the LLM made this tool call the it got this specific response. So this is my request and this is my response. Okay, this is my response and as soon as I got the response the LLM is smart enough to finally summarize that particular output uh that response and give you the output and this is what I'm actually looking for. Okay. Now you need to really understand over here the kind of task that is happening right a request is going I'm getting the information I'm getting giving back the response this is basically happening by an AI agent just a single AI agent I can consider this as an AI agent okay here my main aim is that I have asked an input saying that hey give me the some current information about today AI news I really want to see for this particular date AI news which my LLM was not able to do it. So what it has done is that the LLM is smart enough to understand which tool to probably call and based on this tool call functional it is calling this and it is getting the response.\"),\n",
       " Document(metadata={}, page_content=\"able to do it. So what it has done is that the LLM is smart enough to understand which tool to probably call and based on this tool call functional it is calling this and it is getting the response. So this is a specific task okay and this task is basically solved by this tavly okay tavly which is responsible for the internet search. So this task can be considered as an AI agent. Okay, for a specific task we have defined this. Okay, very simple definition. Okay, so for a specific task we are able to probably go ahead and call this and we are getting the response. Now the question rises, now the question rises then what is agentic AI? AI agents have understood okay fine for a specific task I'm calling something from the LLM, right? The LM is responsible for making that tool call and getting the output and summarizing the output and giving it over here. Here also we can add the prompt. Here also once I get the response I can add the prompt and based on that I can summarize the output. I\"),\n",
       " Document(metadata={}, page_content=\"the output and summarizing the output and giving it over here. Here also we can add the prompt. Here also once I get the response I can add the prompt and based on that I can summarize the output. I can do that. Okay. But this is only for one kind of task. Now if I talk about agentic AI okay and for discussing about the agentic AI application let's consider that let's consider that I have a task and this task is nothing but let's consider I want to probably convert a YT video that I really want to upload to a blog okay to a blog and now to convert a YT video YouTube video into a blog let's say that I have been uploading so many videos. Just imagine if I just create an agenti system which takes my YouTube video and convert that into a blog and publish it in my website. Would it will that not be good? It will definitely be good. Right now here if I probably see I can divide this into multiple subtask. First of all I will take this YT video. I will convert I will take the transcript from\"),\n",
       " Document(metadata={}, page_content=\"be good? It will definitely be good. Right now here if I probably see I can divide this into multiple subtask. First of all I will take this YT video. I will convert I will take the transcript from the YT video. Transcript from the YT video. Okay. After considering the transcript from this my second task will be creating title. Creating title. Okay. Third it can be creating description. Okay. So this will be my third task creating description and my fourth task will be writing the conclusion. Let's say so I've defined this task into four different task right four different tasks. Now for the same task, don't you think converting a YT YT video into transcript, I can create one AI agent. Then similarly for my second AI agent, I can basically take this transcript and this AI agent should be able to give me the title. Yeah. Yeah. And just to show you how these things will happen, don't you think I can just go ahead see this? Okay, see this magic. Okay. So, so what what I will be doing is\"),\n",
       " Document(metadata={}, page_content=\"able to give me the title. Yeah. Yeah. And just to show you how these things will happen, don't you think I can just go ahead see this? Okay, see this magic. Okay. So, so what what I will be doing is that my first task will be that this AI agent will be responsible in getting me the transcript from my YouTube video. Okay. This AI agent will be responsible for creating the title from the transcript that I get. Okay. Then my next agent over here which will be parallelly will be responsible to probably create the description from this particular transcript. Yeah. And finally, don't you think I can have one more one more AI agent which will be responsible in creating the conclusion. Right? Now here this is my AI agent one. Let's consider this. Okay. So this is my AI agent one. This is my AI agent 2. This is my AI agent three. And this is my AI agent 4. Each and every agent can use LLM. It can use prompt to perform its task. Each each here it can or it cannot it is not composite it needs\"),\n",
       " Document(metadata={}, page_content='agent 2. This is my AI agent three. And this is my AI agent 4. Each and every agent can use LLM. It can use prompt to perform its task. Each each here it can or it cannot it is not composite it needs to use all the LLM but since we are working with respect to text related things then obviously we can use LLM okay for now this is just like a one kind of workflow so this workflow goes on like this right so first of all I give my YT video URL YT video URL then this agent is responsible in taking from this and giving the output a transcript. Now this transcript is sent to all the agents and finally we can combine all these outputs and give my final blog. Right? So what does this basically mean? Before an AI agent only used to do one task in an agentic AI system. So this is my entire complex workflow with respect to my agentic AI system and this is performing this entire task together. Here every agent is communicating with each other. Right? I can add one more thing over here. I can add'),\n",
       " Document(metadata={}, page_content=\"workflow with respect to my agentic AI system and this is performing this entire task together. Here every agent is communicating with each other. Right? I can add one more thing over here. I can add human feedback. Human feedback also over here. So here what is basically happening? AI agents are communicating with each other. Right. I can also make sure to probably before this AI agent, let's say this agent is responsible in probably creating a description. For creating a description, it also wants the title. So it will just go ahead this AI agent 2 whatever output it is creating for the title, it will give it to the agent 3. And this will take that information and do this. So internally you'll be able to see we can also make this agent communicate with each other to solve a complex workflow and finally achieve a goal. Right? So just to understand what is the difference between AI agents versus agentic AI here AI agent is doing only one task. In an agentic AI system this AI agents\"),\n",
       " Document(metadata={}, page_content=\"and finally achieve a goal. Right? So just to understand what is the difference between AI agents versus agentic AI here AI agent is doing only one task. In an agentic AI system this AI agents will be collaborating with each other. This is really important. Collaborating collaborating with each other to solve a goal. This is really really important to understand. So I hope you understood this particular video. I hope you liked this particular video. This was the basic differences between generative AI versus AI agent versus agentic AI. And I hope you are able to understand this. Okay. Similar kind of videos I'm also going to come up in this specific series so that you get your fundamental rights. I hope you like this particular video. This was it from my side. I'll see you in the next video. Have a great day. Thank you and all. Take care. Bye-bye.\")]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbde9c59",
   "metadata": {},
   "source": [
    "# Indexing , embedding, vectore storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "87b8b3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\")\n",
    "vector_store = FAISS.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "096a0b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'd3d31e11-43ad-4540-bfad-679a97bfff9f',\n",
       " 1: 'ee72e1e0-b463-4509-8e7d-3dbc3a42bde3',\n",
       " 2: 'd6898f83-20a5-461e-96aa-331fbd932689',\n",
       " 3: '1928410c-0ead-497a-9f45-f44efa985376',\n",
       " 4: '37585228-c29c-4d65-803b-b6f6350763ec',\n",
       " 5: '478c4cdc-bd39-4bb8-8cff-5f31fbb55c82',\n",
       " 6: '9975fe74-11d3-4c0f-932e-77cb6b4f5dfa',\n",
       " 7: 'da8821b5-3b35-4bc6-8c59-c5d7263495fe',\n",
       " 8: '0225bbc5-b5e0-4bbc-8d32-92598bb59bcf',\n",
       " 9: 'c1218f82-0975-43a9-af6e-b5660a60924c',\n",
       " 10: '1c30a2bf-67fe-4596-bf0f-e3f528c173e7',\n",
       " 11: '90cf7988-ad33-4cb0-8028-fb518147f6d9',\n",
       " 12: '58a13d7c-06a1-4f06-a2dd-061b6fe1a2d8',\n",
       " 13: 'ead4e994-4dd0-4cdd-9017-cef9a10acae1',\n",
       " 14: '01b6b36b-5305-4dc4-8376-a6bfcb31f30c',\n",
       " 15: '792e788f-b6c2-421d-a83b-09bde25764b8',\n",
       " 16: '26de53dc-9b20-4e36-8e9a-17936dd87bce',\n",
       " 17: '708b40ec-4a16-4ab4-8b69-3aabf8da20be',\n",
       " 18: 'dd7e73e9-2c22-4711-9bfe-380ff14226c5',\n",
       " 19: 'ed028c43-6887-4caa-84e3-ce1ecd5e7919'}"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.index_to_docstore_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "6c346eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GoogleGenerativeAIEmbeddings(client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x000002077EB5F0D0>, model='models/embedding-001', task_type=None, google_api_key=SecretStr('**********'), credentials=None, client_options=None, transport=None, request_options=None)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8909df19",
   "metadata": {},
   "source": [
    "# Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "a7132dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type = \"similarity\", search_kwargs={\"k\":4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "611c4d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002077EB5D300>, search_kwargs={'k': 4})"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "ced4bb94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='d3d31e11-43ad-4540-bfad-679a97bfff9f', metadata={}, page_content=\"Hello all, my name is Krishna and welcome to my YouTube channel. So guys, today in this particular video we are going to discuss about the basic differences between generative AI versus AI agents versus agentic AI. Now this is one of the most trending topics that is currently going on and it is necessary that you need to have your understanding very much clear when you are specifically working in all the specific topics. Okay. So one by one we will try to understand about each and every topics that I have actually mentioned over here. We'll go step by step. Okay. So first thing is that I hope you may be knowing large language models. Okay. You may be knowing about large image models also. Right? So let's say that I'll also go ahead and write large image models. When we talk about large language models or large image model, these models are actually very huge models, right? These are like huge models, bigger models, right? It can be of billions of parameters and they have trained with\"),\n",
       " Document(id='90cf7988-ad33-4cb0-8028-fb518147f6d9', metadata={}, page_content=\"able to provide the response for this particular input, it will keep on looking for external things that will be able to handle this particular input. Now in this particular case when I ask the input saying that hey what is the current news? What is the current news for this specific date that is today's date? The LLM will not be able to give the answer. So the LLM will look for whether it is connected to any third-party APIs, third party APIs or data source from which I will be able to get this kind of information. So that is where it will be making the specific tool call. Okay, it will be making the specific tool call. Now this tool call will be something like this. The tool call will be made and based on this I will be getting a response. Okay, I'll be getting a response. Now the as soon as the LLM made this tool call the it got this specific response. So this is my request and this is my response. Okay, this is my response and as soon as I got the response the LLM is smart enough\"),\n",
       " Document(id='c1218f82-0975-43a9-af6e-b5660a60924c', metadata={}, page_content=\"to generate the new content. But what about the current information? Okay, it will not be able to give you, right? Let's say that I'm going to ask some specific information of a company. Obviously this LLM will not be trained with that company data because the company data will be private to that company itself. Right? So that way also that LLM will not be able to give you that unless and until it is connected to some kind of external database or external data source. This is just one example now what is basically happening is that as soon as I asked a question hey who won this particular match within RCB or any other place any other um any other team that happened today it will not be able to give you the output. So what it will be dependent on it will be dependent on the third party source. Let's say there is one third party source I will consider in this particular scenario. I will just go ahead and connect it to some kind of database. Okay. Let's say one of the data source is\"),\n",
       " Document(id='0225bbc5-b5e0-4bbc-8d32-92598bb59bcf', metadata={}, page_content=\"using this specific model. Okay. Now you know that all these LLM or LM models they're trained with some specific past data okay they don't have like let's say if I ask this particular LLM hey what is the news for today or hey or who won this particular IPL match between this and this like let's say Bangalore is going to happen have some matches tomorrow or today if it has right and LLM will not know the result because it's not connected to the internet okay so in that kind of scenario Whenever I ask this particular question, the LLM will not be able to give an output to us. Okay, obviously it will not be able to give because it does not have that specific information. Now, this is one major disadvantage of LLM, right? Yes, LLM will be able to generate new content. These models will be able to generate the new content. But what about the current information? Okay, it will not be able to give you, right? Let's say that I'm going to ask some specific information of a company. Obviously\")]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"who is krishna\") # Ask question related to the video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f199e0ff",
   "metadata": {},
   "source": [
    "# Step 3 : Augmentaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "48201efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model='gemini-2.0-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "67123948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGoogleGenerativeAI(model='models/gemini-2.0-flash', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x000002077EB5F220>, default_metadata=())"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "460800e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are a helpful assistant.\n",
    "    Answer only from the provided transcript context.\n",
    "    If the context is insufficient, just say you don't know.\n",
    "    {context}\n",
    "    Question : {question}\n",
    "    \"\"\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "333fcc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"is the topic of LLM discussed in the video? If yes then tell me what discussed ?\"\n",
    "retrived_docs = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "d8dae335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='0225bbc5-b5e0-4bbc-8d32-92598bb59bcf', metadata={}, page_content=\"using this specific model. Okay. Now you know that all these LLM or LM models they're trained with some specific past data okay they don't have like let's say if I ask this particular LLM hey what is the news for today or hey or who won this particular IPL match between this and this like let's say Bangalore is going to happen have some matches tomorrow or today if it has right and LLM will not know the result because it's not connected to the internet okay so in that kind of scenario Whenever I ask this particular question, the LLM will not be able to give an output to us. Okay, obviously it will not be able to give because it does not have that specific information. Now, this is one major disadvantage of LLM, right? Yes, LLM will be able to generate new content. These models will be able to generate the new content. But what about the current information? Okay, it will not be able to give you, right? Let's say that I'm going to ask some specific information of a company. Obviously\"),\n",
       " Document(id='c1218f82-0975-43a9-af6e-b5660a60924c', metadata={}, page_content=\"to generate the new content. But what about the current information? Okay, it will not be able to give you, right? Let's say that I'm going to ask some specific information of a company. Obviously this LLM will not be trained with that company data because the company data will be private to that company itself. Right? So that way also that LLM will not be able to give you that unless and until it is connected to some kind of external database or external data source. This is just one example now what is basically happening is that as soon as I asked a question hey who won this particular match within RCB or any other place any other um any other team that happened today it will not be able to give you the output. So what it will be dependent on it will be dependent on the third party source. Let's say there is one third party source I will consider in this particular scenario. I will just go ahead and connect it to some kind of database. Okay. Let's say one of the data source is\"),\n",
       " Document(id='d6898f83-20a5-461e-96aa-331fbd932689', metadata={}, page_content=\"can generate video frames, it can generate anything as such, right? audio it can also generate audio right and it can also generate videos so I've written each and everything about over here right so here what this LLM is basically doing since it is trained with huge amount of data in short it is basically generating new content whenever we try to give any kind of input right if I say hey please generate a new image related to aentic AI so this LLA model it if it has that multimodel capabilities it will be able to generate that particular image or video whatever specific things we require whenever we talk in this specific way this is something related to generative AI okay so this is something related to generative AI right now when we say hey uh let's go ahead and build a generative AI application wherein we create a chatbot okay and that chatbot should be able to do this specific ch uh task wherein the main aim is generating new content you can definitely do it right so There we\"),\n",
       " Document(id='90cf7988-ad33-4cb0-8028-fb518147f6d9', metadata={}, page_content=\"able to provide the response for this particular input, it will keep on looking for external things that will be able to handle this particular input. Now in this particular case when I ask the input saying that hey what is the current news? What is the current news for this specific date that is today's date? The LLM will not be able to give the answer. So the LLM will look for whether it is connected to any third-party APIs, third party APIs or data source from which I will be able to get this kind of information. So that is where it will be making the specific tool call. Okay, it will be making the specific tool call. Now this tool call will be something like this. The tool call will be made and based on this I will be getting a response. Okay, I'll be getting a response. Now the as soon as the LLM made this tool call the it got this specific response. So this is my request and this is my response. Okay, this is my response and as soon as I got the response the LLM is smart enough\")]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrived_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "b6d25902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"using this specific model. Okay. Now you know that all these LLM or LM models they're trained with some specific past data okay they don't have like let's say if I ask this particular LLM hey what is the news for today or hey or who won this particular IPL match between this and this like let's say Bangalore is going to happen have some matches tomorrow or today if it has right and LLM will not know the result because it's not connected to the internet okay so in that kind of scenario Whenever I ask this particular question, the LLM will not be able to give an output to us. Okay, obviously it will not be able to give because it does not have that specific information. Now, this is one major disadvantage of LLM, right? Yes, LLM will be able to generate new content. These models will be able to generate the new content. But what about the current information? Okay, it will not be able to give you, right? Let's say that I'm going to ask some specific information of a company. Obviously\\n\\nto generate the new content. But what about the current information? Okay, it will not be able to give you, right? Let's say that I'm going to ask some specific information of a company. Obviously this LLM will not be trained with that company data because the company data will be private to that company itself. Right? So that way also that LLM will not be able to give you that unless and until it is connected to some kind of external database or external data source. This is just one example now what is basically happening is that as soon as I asked a question hey who won this particular match within RCB or any other place any other um any other team that happened today it will not be able to give you the output. So what it will be dependent on it will be dependent on the third party source. Let's say there is one third party source I will consider in this particular scenario. I will just go ahead and connect it to some kind of database. Okay. Let's say one of the data source is\\n\\ncan generate video frames, it can generate anything as such, right? audio it can also generate audio right and it can also generate videos so I've written each and everything about over here right so here what this LLM is basically doing since it is trained with huge amount of data in short it is basically generating new content whenever we try to give any kind of input right if I say hey please generate a new image related to aentic AI so this LLA model it if it has that multimodel capabilities it will be able to generate that particular image or video whatever specific things we require whenever we talk in this specific way this is something related to generative AI okay so this is something related to generative AI right now when we say hey uh let's go ahead and build a generative AI application wherein we create a chatbot okay and that chatbot should be able to do this specific ch uh task wherein the main aim is generating new content you can definitely do it right so There we\\n\\nable to provide the response for this particular input, it will keep on looking for external things that will be able to handle this particular input. Now in this particular case when I ask the input saying that hey what is the current news? What is the current news for this specific date that is today's date? The LLM will not be able to give the answer. So the LLM will look for whether it is connected to any third-party APIs, third party APIs or data source from which I will be able to get this kind of information. So that is where it will be making the specific tool call. Okay, it will be making the specific tool call. Now this tool call will be something like this. The tool call will be made and based on this I will be getting a response. Okay, I'll be getting a response. Now the as soon as the LLM made this tool call the it got this specific response. So this is my request and this is my response. Okay, this is my response and as soon as I got the response the LLM is smart enough\""
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_text = \"\\n\\n\".join(doc.page_content for doc in retrived_docs)\n",
    "context_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "4cedf87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text=\"\\n    You are a helpful assistant.\\n    Answer only from the provided transcript context.\\n    If the context is insufficient, just say you don't know.\\n    using this specific model. Okay. Now you know that all these LLM or LM models they're trained with some specific past data okay they don't have like let's say if I ask this particular LLM hey what is the news for today or hey or who won this particular IPL match between this and this like let's say Bangalore is going to happen have some matches tomorrow or today if it has right and LLM will not know the result because it's not connected to the internet okay so in that kind of scenario Whenever I ask this particular question, the LLM will not be able to give an output to us. Okay, obviously it will not be able to give because it does not have that specific information. Now, this is one major disadvantage of LLM, right? Yes, LLM will be able to generate new content. These models will be able to generate the new content. But what about the current information? Okay, it will not be able to give you, right? Let's say that I'm going to ask some specific information of a company. Obviously\\n\\nto generate the new content. But what about the current information? Okay, it will not be able to give you, right? Let's say that I'm going to ask some specific information of a company. Obviously this LLM will not be trained with that company data because the company data will be private to that company itself. Right? So that way also that LLM will not be able to give you that unless and until it is connected to some kind of external database or external data source. This is just one example now what is basically happening is that as soon as I asked a question hey who won this particular match within RCB or any other place any other um any other team that happened today it will not be able to give you the output. So what it will be dependent on it will be dependent on the third party source. Let's say there is one third party source I will consider in this particular scenario. I will just go ahead and connect it to some kind of database. Okay. Let's say one of the data source is\\n\\ncan generate video frames, it can generate anything as such, right? audio it can also generate audio right and it can also generate videos so I've written each and everything about over here right so here what this LLM is basically doing since it is trained with huge amount of data in short it is basically generating new content whenever we try to give any kind of input right if I say hey please generate a new image related to aentic AI so this LLA model it if it has that multimodel capabilities it will be able to generate that particular image or video whatever specific things we require whenever we talk in this specific way this is something related to generative AI okay so this is something related to generative AI right now when we say hey uh let's go ahead and build a generative AI application wherein we create a chatbot okay and that chatbot should be able to do this specific ch uh task wherein the main aim is generating new content you can definitely do it right so There we\\n\\nable to provide the response for this particular input, it will keep on looking for external things that will be able to handle this particular input. Now in this particular case when I ask the input saying that hey what is the current news? What is the current news for this specific date that is today's date? The LLM will not be able to give the answer. So the LLM will look for whether it is connected to any third-party APIs, third party APIs or data source from which I will be able to get this kind of information. So that is where it will be making the specific tool call. Okay, it will be making the specific tool call. Now this tool call will be something like this. The tool call will be made and based on this I will be getting a response. Okay, I'll be getting a response. Now the as soon as the LLM made this tool call the it got this specific response. So this is my request and this is my response. Okay, this is my response and as soon as I got the response the LLM is smart enough\\n    Question : is the topic of LLM discussed in the video? If yes then tell me what discussed ?\\n    \")"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompt = prompt.invoke({\"context\": context_text, \"question\": question})\n",
    "final_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c0d518",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "9476d3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, the video discusses LLMs and their limitations, specifically that they are not connected to the internet and cannot provide current information. It also mentions that LLMs can generate new content but may not have specific information about a company unless connected to an external database. The video further explains how LLMs can use third-party sources or APIs to answer questions they don't have the information for, by making tool calls to external data sources. It also mentions that LLMs with multimodal capabilities can generate images and videos.\n"
     ]
    }
   ],
   "source": [
    "answer = llm.invoke(final_prompt)\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb64b46",
   "metadata": {},
   "source": [
    "# Building a Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "278a98de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "af4a5bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(retrieved_docs):\n",
    "  context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "  return context_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "0f744715",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_chain = RunnableParallel({\n",
    "    'context': retriever | RunnableLambda(format_docs),\n",
    "    'question': RunnablePassthrough()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "297a27af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': \"Hello all, my name is Krishna and welcome to my YouTube channel. So guys, today in this particular video we are going to discuss about the basic differences between generative AI versus AI agents versus agentic AI. Now this is one of the most trending topics that is currently going on and it is necessary that you need to have your understanding very much clear when you are specifically working in all the specific topics. Okay. So one by one we will try to understand about each and every topics that I have actually mentioned over here. We'll go step by step. Okay. So first thing is that I hope you may be knowing large language models. Okay. You may be knowing about large image models also. Right? So let's say that I'll also go ahead and write large image models. When we talk about large language models or large image model, these models are actually very huge models, right? These are like huge models, bigger models, right? It can be of billions of parameters and they have trained with\\n\\nable to provide the response for this particular input, it will keep on looking for external things that will be able to handle this particular input. Now in this particular case when I ask the input saying that hey what is the current news? What is the current news for this specific date that is today's date? The LLM will not be able to give the answer. So the LLM will look for whether it is connected to any third-party APIs, third party APIs or data source from which I will be able to get this kind of information. So that is where it will be making the specific tool call. Okay, it will be making the specific tool call. Now this tool call will be something like this. The tool call will be made and based on this I will be getting a response. Okay, I'll be getting a response. Now the as soon as the LLM made this tool call the it got this specific response. So this is my request and this is my response. Okay, this is my response and as soon as I got the response the LLM is smart enough\\n\\nto generate the new content. But what about the current information? Okay, it will not be able to give you, right? Let's say that I'm going to ask some specific information of a company. Obviously this LLM will not be trained with that company data because the company data will be private to that company itself. Right? So that way also that LLM will not be able to give you that unless and until it is connected to some kind of external database or external data source. This is just one example now what is basically happening is that as soon as I asked a question hey who won this particular match within RCB or any other place any other um any other team that happened today it will not be able to give you the output. So what it will be dependent on it will be dependent on the third party source. Let's say there is one third party source I will consider in this particular scenario. I will just go ahead and connect it to some kind of database. Okay. Let's say one of the data source is\\n\\nusing this specific model. Okay. Now you know that all these LLM or LM models they're trained with some specific past data okay they don't have like let's say if I ask this particular LLM hey what is the news for today or hey or who won this particular IPL match between this and this like let's say Bangalore is going to happen have some matches tomorrow or today if it has right and LLM will not know the result because it's not connected to the internet okay so in that kind of scenario Whenever I ask this particular question, the LLM will not be able to give an output to us. Okay, obviously it will not be able to give because it does not have that specific information. Now, this is one major disadvantage of LLM, right? Yes, LLM will be able to generate new content. These models will be able to generate the new content. But what about the current information? Okay, it will not be able to give you, right? Let's say that I'm going to ask some specific information of a company. Obviously\",\n",
       " 'question': 'who is Krishna'}"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_chain.invoke('who is Krishna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "e4ad658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "b9ca4774",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_chain = parallel_chain | prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "a59e5d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The video discusses converting a YouTube video into a blog post using an agentic AI system. The process involves dividing the task into subtasks and assigning each subtask to an AI agent. The subtasks include:\\n\\n1.  Converting the YouTube video into a transcript.\\n2.  Creating a title from the transcript.\\n3.  Creating a description from the transcript.\\n4.  Writing a conclusion.\\n\\nEach AI agent can use LLMs and prompts to perform its task. The first AI agent retrieves the transcript from the YouTube video, and then the transcript is sent to the other agents. The agents then create the title, description, and conclusion, respectively. Finally, the outputs from all the agents are combined to create the final blog post.'"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_chain.invoke('Summarize the video')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
